#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã czbooks.net
"""
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup

def analyze_czbooks_structure(url):
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã czbooks.net"""

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    chrome_options.binary_location = '/usr/bin/chromium-browser'

    driver = None
    try:
        print(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)

        # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ JavaScript
        print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ JavaScript...")
        time.sleep(5)

        # –ü–æ–ª—É—á–∞–µ–º HTML
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        print("\n" + "="*60)
        print("üìä –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ CZBOOKS.NET")
        print("="*60)

        # 1. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–Ω–∏–≥–µ
        print("\n1Ô∏è‚É£ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ö–ù–ò–ì–ï:")
        print("-" * 40)

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_selectors = ['h1', '.book-title', '.novel-title', '[class*="title"]']
        for selector in title_selectors:
            elem = soup.select_one(selector)
            if elem:
                print(f"  üìñ –ó–∞–≥–æ–ª–æ–≤–æ–∫ [{selector}]: {elem.get_text(strip=True)[:80]}")

        # –ê–≤—Ç–æ—Ä
        author_selectors = ['.author', '[class*="author"]', '.writer', '[rel="author"]']
        for selector in author_selectors:
            elem = soup.select_one(selector)
            if elem:
                print(f"  ‚úçÔ∏è –ê–≤—Ç–æ—Ä [{selector}]: {elem.get_text(strip=True)[:80]}")

        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_selectors = ['.description', '.synopsis', '[class*="desc"]', '.intro']
        for selector in desc_selectors:
            elem = soup.select_one(selector)
            if elem:
                print(f"  üìù –û–ø–∏—Å–∞–Ω–∏–µ [{selector}]: {elem.get_text(strip=True)[:80]}...")

        # 2. –°–ø–∏—Å–æ–∫ –≥–ª–∞–≤
        print("\n2Ô∏è‚É£ –°–ü–ò–°–û–ö –ì–õ–ê–í:")
        print("-" * 40)

        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–æ —Å–ø–∏—Å–∫–æ–º –≥–ª–∞–≤
        chapter_containers = [
            '.chapter-list',
            '.chapters',
            '[class*="chapter"]',
            '#chapters',
            '.toc',
            '[class*="catalog"]'
        ]

        for selector in chapter_containers:
            container = soup.select_one(selector)
            if container:
                print(f"  üìö –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –≥–ª–∞–≤: {selector}")
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –≥–ª–∞–≤—ã
                chapter_links = container.find_all('a', href=True)
                print(f"  üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(chapter_links)}")

                if chapter_links:
                    print("\n  –ü—Ä–∏–º–µ—Ä—ã –≥–ª–∞–≤:")
                    for i, link in enumerate(chapter_links[:5], 1):
                        href = link.get('href', '')
                        title = link.get_text(strip=True)
                        print(f"    {i}. {title[:50]}")
                        print(f"       URL: {href}")
                    break

        # 3. –í—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≥–ª–∞–≤—ã (–ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ)
        print("\n3Ô∏è‚É£ –ü–û–ò–°–ö –°–°–´–õ–û–ö –ù–ê –ì–õ–ê–í–´:")
        print("-" * 40)

        all_links = soup.find_all('a', href=True)
        chapter_links = []

        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ —ç—Ç–æ –Ω–∞ —Å—Å—ã–ª–∫—É –Ω–∞ –≥–ª–∞–≤—É
            if any(keyword in href.lower() for keyword in ['chapter', 'ch', 'read', 'c_']):
                chapter_links.append({'href': href, 'text': text})

        print(f"  üîó –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –≥–ª–∞–≤—ã: {len(chapter_links)}")
        if chapter_links:
            print("\n  –ü–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫:")
            for i, ch in enumerate(chapter_links[:5], 1):
                print(f"    {i}. {ch['text'][:50]}")
                print(f"       {ch['href']}")

        # 4. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ URL
        print("\n4Ô∏è‚É£ –ê–ù–ê–õ–ò–ó URL:")
        print("-" * 40)
        print(f"  üåê –ë–∞–∑–æ–≤—ã–π URL: {url}")

        if chapter_links:
            example_href = chapter_links[0]['href']
            print(f"  üìÑ –ü—Ä–∏–º–µ—Ä URL –≥–ª–∞–≤—ã: {example_href}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            if example_href.startswith('http'):
                print(f"  ‚úÖ –ê–±—Å–æ–ª—é—Ç–Ω—ã–π URL")
            elif example_href.startswith('/'):
                print(f"  ‚úÖ –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π URL (–æ—Ç –∫–æ—Ä–Ω—è)")
            else:
                print(f"  ‚úÖ –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π URL (–æ—Ç —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã)")

        # 5. JavaScript –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        print("\n5Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê JAVASCRIPT:")
        print("-" * 40)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–Ω–æ–ø–æ–∫ "–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ"
        load_more_buttons = soup.find_all(['button', 'a'], string=lambda s: s and any(
            keyword in s.lower() for keyword in ['load more', '–ø–æ–∫–∞–∑–∞—Ç—å –µ—â–µ', 'Êõ¥Â§ö', 'more']
        ))

        if load_more_buttons:
            print(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –∫–Ω–æ–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {len(load_more_buttons)}")
            print("  üí° –í–æ–∑–º–æ–∂–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥—Ä—É–∑–∫–∞ –≥–ª–∞–≤")
        else:
            print(f"  ‚úÖ –ö–Ω–æ–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            print("  üí° –í–µ—Ä–æ—è—Ç–Ω–æ, –≤—Å–µ –≥–ª–∞–≤—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è —Å—Ä–∞–∑—É")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        pagination = soup.find_all(['a', 'button'], class_=lambda c: c and any(
            keyword in c.lower() for keyword in ['page', 'pag', 'next', 'prev']
        ))

        if pagination:
            print(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏—è: {len(pagination)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            print("  üí° –ì–ª–∞–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
        else:
            print(f"  ‚úÖ –ü–∞–≥–∏–Ω–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        print("\n6Ô∏è‚É£ –°–û–•–†–ê–ù–ï–ù–ò–ï HTML:")
        print("-" * 40)

        with open('/home/user/novelbins-epub/czbooks_sample.html', 'w', encoding='utf-8') as f:
            f.write(html)
        print("  üíæ HTML —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: czbooks_sample.html")

        # 7. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print("\n7Ô∏è‚É£ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print("-" * 40)

        # –ö–ª–∞—Å—Å—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        main_containers = soup.find_all(['main', 'article', 'section'])
        print(f"  üì¶ –û—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(main_containers)}")

        for container in main_containers[:3]:
            classes = container.get('class', [])
            if classes:
                print(f"    - –ö–ª–∞—Å—Å: {' '.join(classes)}")

        # ID —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        elements_with_id = soup.find_all(id=True)
        print(f"  üÜî –≠–ª–µ–º–µ–Ω—Ç–æ–≤ —Å ID: {len(elements_with_id)}")

        important_ids = [elem.get('id') for elem in elements_with_id if any(
            keyword in elem.get('id', '').lower()
            for keyword in ['chapter', 'book', 'novel', 'content', 'list']
        )]

        if important_ids:
            print("  üìå –í–∞–∂–Ω—ã–µ ID:")
            for id_name in important_ids[:5]:
                print(f"    - #{id_name}")

        print("\n" + "="*60)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        print("="*60)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

    finally:
        if driver:
            driver.quit()


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π URL
    test_url = "https://czbooks.net/n/ul6pe"
    analyze_czbooks_structure(test_url)
