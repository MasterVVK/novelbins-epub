#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –≥–ª–æ—Å—Å–∞—Ä–∏—è
"""
import sys
sys.path.insert(0, '/home/user/novelbins-epub/web_app')

from app import create_app, db
from app.models import Novel, GlossaryItem
from app.services.glossary_optimizer import GlossaryOptimizer
import json

def test_optimizer():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ –Ω–æ–≤–µ–ª–ª–µ ISSTH"""
    
    app = create_app()
    with app.app_context():
        # –ù–∞–π—Ç–∏ –Ω–æ–≤–µ–ª–ª—É
        novel = Novel.query.filter(Novel.title.like('%–∑–∞–ø–µ—á–∞—Ç–∞—Ç—å%')).first()
        
        if not novel:
            print("‚ùå –ù–æ–≤–µ–ª–ª–∞ '–Ø —Ö–æ—á—É –∑–∞–ø–µ—á–∞—Ç–∞—Ç—å –Ω–µ–±–µ—Å–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–µ–ª–ª–∞: {novel.title} (ID: {novel.id})")
        
        # –ê–Ω–∞–ª–∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è
        print("\nüìä –ê–ù–ê–õ–ò–ó –ì–õ–û–°–°–ê–†–ò–Ø")
        print("=" * 60)
        
        stats = GlossaryOptimizer.optimize_novel_glossary(novel.id, auto_remove=False)
        
        print(f"–í—Å–µ–≥–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {stats['total']}")
        print(f"–î–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {len(stats['to_remove'])} ({stats.get('remove_percent', 0):.1f}%)")
        print(f"–î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {len(stats['to_keep'])} ({stats.get('keep_percent', 0):.1f}%)")
        print(f"–¢—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(stats['to_review'])} ({stats.get('review_percent', 0):.1f}%)")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        if stats['to_remove']:
            print("\nüóëÔ∏è –ü–†–ò–ú–ï–†–´ –¢–ï–†–ú–ò–ù–û–í –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø:")
            print("-" * 40)
            for term in stats['to_remove'][:10]:
                print(f"  [{term['category']}] {term['chinese']} ‚Üí {term['russian']}")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        if stats['to_review']:
            print("\n‚ö†Ô∏è –¢–ï–†–ú–ò–ù–´, –¢–†–ï–ë–£–Æ–©–ò–ï –ü–†–û–í–ï–†–ö–ò:")
            print("-" * 40)
            for term in stats['to_review'][:5]:
                print(f"  [{term['category']}] {term['chinese']} ‚Üí {term['russian']}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        print("\nüí° –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
        print("-" * 40)
        
        suggestions = GlossaryOptimizer.get_optimization_suggestions(novel.id, limit=10)
        
        for suggestion in suggestions:
            print(f"  [{suggestion['recommendation']}] {suggestion['chinese']} ‚Üí {suggestion['russian']}")
            print(f"    –ü—Ä–∏—á–∏–Ω–∞: {suggestion['reason']}")
        
        # –¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        print("\nüîç –¢–ï–°–¢ –ö–û–ù–ö–†–ï–¢–ù–´–• –¢–ï–†–ú–ò–ù–û–í:")
        print("-" * 40)
        
        test_terms = [
            ('Âïä', '–∞—Ö', 'emotions_and_sounds'),
            ('‰øÆÁÇº', '–∫—É–ª—å—Ç–∏–≤–∞—Ü–∏—è', 'cultivation_terms'),
            ('Âπ¥', '–≥–æ–¥', 'time_periods'),
            ('Â≠üÊµ©', '–ú—ç–Ω –•–∞–æ', 'characters'),
            ('ÁÅµÁü≥', '–¥—É—Ö–æ–≤–Ω—ã–µ –∫–∞–º–Ω–∏', 'currency')
        ]
        
        for chinese, russian, category in test_terms:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
            test_item = GlossaryItem(
                english_term=chinese,
                russian_term=russian,
                category=category,
                novel_id=novel.id
            )
            
            result = GlossaryOptimizer.analyze_glossary_item(test_item)
            print(f"  {chinese} ‚Üí {russian}: {result}")
        
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report = {
            'novel': novel.title,
            'statistics': {
                'total': stats['total'],
                'to_remove': len(stats['to_remove']),
                'to_keep': len(stats['to_keep']),
                'to_review': len(stats['to_review'])
            },
            'remove_examples': stats['to_remove'][:20],
            'review_examples': stats['to_review'][:10],
            'suggestions': suggestions
        }
        
        with open('/home/user/novelbins-epub/glossary_optimizer_test_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ glossary_optimizer_test_report.json")

if __name__ == '__main__':
    test_optimizer()