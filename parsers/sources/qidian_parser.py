#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä Qidian –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–±–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π —Å–∞–π—Ç–∞
"""
import time
import random
from typing import Dict, List, Optional
from bs4 import BeautifulSoup
import re
import sys
import os
import base64
import json
import zlib

# –ò–º–ø–æ—Ä—Ç Selenium –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    selenium_available = True
except ImportError:
    selenium_available = False

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –±–∞–∑–æ–≤–æ–º—É –∫–ª–∞—Å—Å—É
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'base'))
from base_parser import BaseParser


class QidianParser(BaseParser):
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è Qidian.com (–∫–∏—Ç–∞–π—Å–∫–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –≤–µ–±-–Ω–æ–≤–µ–ª–ª)
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –æ—Ç –±–æ—Ç–æ–≤
    """
    
    def __init__(self, auth_cookies: str = None, socks_proxy: str = None):
        super().__init__("qidian")
        
        # –ü—É–ª User-Agent'–æ–≤ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
        self.user_agents = [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Linux; Android 11; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36',
            'Mozilla/5.0 (Linux; Android 10; Mi 9T Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36',
            'Mozilla/5.0 (iPad; CPU OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1'
        ]
        self.current_ua_index = 0
        
        # Cookies –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.auth_cookies = auth_cookies
        
        # SOCKS –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ WAF
        self.socks_proxy = socks_proxy
        if socks_proxy:
            print(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º SOCKS –ø—Ä–æ–∫—Å–∏: {socks_proxy}")
            self._setup_proxy_session()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        self._update_headers()
        
        # –ë–∞–∑–æ–≤—ã–µ URL
        self.mobile_base_url = "https://m.qidian.com"
        
        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–∞—É–∑
        self.consecutive_errors = 0
    
    def _setup_proxy_session(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ —Å SOCKS –ø—Ä–æ–∫—Å–∏"""
        try:
            import requests
            from requests.adapters import HTTPAdapter
            import urllib3
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏
            if ':' in self.socks_proxy:
                proxy_host, proxy_port = self.socks_proxy.split(':', 1)
                proxy_url = f'socks5://{proxy_host}:{proxy_port}'
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —Å –ø—Ä–æ–∫—Å–∏
                proxies = {
                    'http': proxy_url,
                    'https': proxy_url
                }
                
                self.session.proxies.update(proxies)
                print(f"‚úÖ SOCKS –ø—Ä–æ–∫—Å–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {proxy_url}")
            else:
                print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏: {self.socks_proxy}")
                
        except ImportError as e:
            print(f"‚ùå –î–ª—è SOCKS –ø—Ä–æ–∫—Å–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è requests[socks]: {e}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏: {e}")
        
    def _update_headers(self):
        """–û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –Ω–æ–≤—ã–º User-Agent –∏ cookies"""
        headers = {
            'User-Agent': self.user_agents[self.current_ua_index],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º cookies –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.auth_cookies:
            headers['Cookie'] = self.auth_cookies
            print(f"üîê –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é: {len(self.auth_cookies)} —Å–∏–º–≤–æ–ª–æ–≤ cookies")
        
        self.session.headers.update(headers)
        
    def _rotate_user_agent(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π User-Agent"""
        self.current_ua_index = (self.current_ua_index + 1) % len(self.user_agents)
        self._update_headers()
        print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ User-Agent: {self.user_agents[self.current_ua_index][:50]}...")
    
    def get_book_info(self, book_url: str) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–Ω–∏–≥–µ
        """
        book_id = self._extract_book_id(book_url)
        if not book_id:
            raise ValueError(f"–ù–µ —É–¥–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å ID –∫–Ω–∏–≥–∏ –∏–∑ URL: {book_url}")
        
        mobile_url = f"{self.mobile_base_url}/book/{book_id}/"
        html_content = self._get_page_content(mobile_url, description=f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–Ω–∏–≥–µ {book_id}")
        
        if not html_content:
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–Ω–∏–≥–∏: {mobile_url}")
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–Ω–∏–≥–µ
        book_info = {
            'book_id': book_id,
            'title': self._extract_title(soup),
            'author': self._extract_author(soup),
            'status': self._extract_status(soup),
            'genre': self._extract_genre(soup),
            'description': self._extract_description(soup),
            'total_chapters': 0  # –ë—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –≤ get_chapter_list
        }
        
        return book_info
    
    def get_chapter_list(self, book_url: str) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤ –∫–Ω–∏–≥–∏
        """
        book_id = self._extract_book_id(book_url)
        if not book_id:
            raise ValueError(f"–ù–µ —É–¥–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å ID –∫–Ω–∏–≥–∏ –∏–∑ URL: {book_url}")
        
        catalog_url = f"{self.mobile_base_url}/book/{book_id}/catalog"
        html_content = self._get_page_content(catalog_url, description=f"–ö–∞—Ç–∞–ª–æ–≥ –∫–Ω–∏–≥–∏ {book_id}")
        
        if not html_content:
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –∫–Ω–∏–≥–∏: {catalog_url}")
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        chapters = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≥–ª–∞–≤—ã
        chapter_links = soup.select('a[href*="/chapter/"]')
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≥–ª–∞–≤—ã: {len(chapter_links)}")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–ª–∞–≤—ã
        all_chapters = []
        story_chapters = []
        
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞–ª–∏–¥–Ω—ã–µ –≥–ª–∞–≤—ã
        for link in chapter_links:
            title = link.get_text(strip=True)
            href = link.get('href', '')
            
            if href:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π URL –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π
                if href.startswith('//'):
                    chapter_url = f"https:{href}"
                elif href.startswith('/'):
                    chapter_url = f"{self.mobile_base_url}{href}"
                else:
                    chapter_url = href
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º chapter_id –∏–∑ URL
                chapter_id = self._extract_chapter_id(chapter_url)
                
                if chapter_id:
                    chapter_info = {
                        'title': title,
                        'url': chapter_url, 
                        'chapter_id': chapter_id,
                        'is_story_chapter': self._is_story_chapter(title),
                        'word_count': 0
                    }
                    all_chapters.append(chapter_info)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –≥–ª–∞–≤—ã –∏—Å—Ç–æ—Ä–∏–∏ (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "Á¨¨")
        story_chapters = [ch for ch in all_chapters if ch['is_story_chapter']]
        
        if not story_chapters:
            # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥–ª–∞–≤, –±–µ—Ä–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —è–≤–Ω–æ —Å–ª—É–∂–µ–±–Ω—ã—Ö
            print("‚ö†Ô∏è –ü—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ")
            story_chapters = [ch for ch in all_chapters if not self._is_service_chapter(ch['title'])]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ—Ä—è–¥–∫–æ–≤–æ–º—É –Ω–æ–º–µ—Ä—É –≤ URL (chapter_id)
        story_chapters.sort(key=lambda x: int(x['chapter_id']))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ –≥–ª–∞–≤
        for i, chapter in enumerate(story_chapters, 1):
            chapter['number'] = i
            del chapter['is_story_chapter']  # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω–æ–µ –ø–æ–ª–µ
        
        print(f"üìñ –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(story_chapters)}")
        
        if story_chapters:
            print(f"üìã –ü–µ—Ä–≤—ã–µ 3 –≥–ª–∞–≤—ã:")
            for i, ch in enumerate(story_chapters[:3]):
                print(f"   {i+1}. {ch['title']}")
        
        return story_chapters

    def _is_service_chapter(self, title: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≥–ª–∞–≤–∞ —Å–ª—É–∂–µ–±–Ω–æ–π (—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞ –∏ —Ç.–¥.)
        """
        service_keywords = [
            # –°–ª—É–∂–µ–±–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            'Êñ∞‰π¶', 'ÂèëÂ∏É', 'ÈÄöÁü•', 'ÂÖ¨Âëä', 'ËØ¥Êòé', 'ÊäΩÂ•ñ', 'Ê¥ªÂä®',
            'ÊïôÁ®ã', 'Â§ñ‰º†', 'Áï™Â§ñ', 'ÊÑüË®Ä', 'Êé®Ëçê', 'È™óÂ≠ê', 'ÂÜíÂÖÖ',
            'Êµ∑Èáè', 'iPad', 'Ëµ∑ÁÇπÂ∏Å', 'ÁªèÈ™å', 'Êé®ËçêÁ•®',
            # –î–∞—Ç—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö (–ø—Ä–∏–∑–Ω–∞–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π)
            '2022-', '2023-', '2024-', '2025-',
            '‰ΩúÂÆ∂ÂÖ•È©ª', 'Âç≥Êõ¥Âç≥Áúã', 'ËøòÊúâÁï™Â§ñ'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        for keyword in service_keywords:
            if keyword in title:
                return True
        
        # –ì–ª–∞–≤—ã —Å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —á–∞—Å—Ç–æ —Å–ª—É–∂–µ–±–Ω—ã–µ
        if len(title.strip()) < 3:
            return True
        
        # –ì–ª–∞–≤—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–æ–ª—å–∫–æ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º—è
        if '19:00' in title or '‰ΩúÂÆ∂ÂÖ•È©ª' in title:
            return True
            
        return False

    def _is_story_chapter(self, title: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≥–ª–∞–≤–∞ —á–∞—Å—Ç—å—é –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
        """
        # –ì–ª–∞–≤—ã –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å "Á¨¨" (–≥–ª–∞–≤–∞) –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω–æ–º–µ—Ä
        if title.startswith('Á¨¨') and ('Á´†' in title or 'Âõû' in title):
            return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≥–ª–∞–≤ –∏—Å—Ç–æ—Ä–∏–∏
        story_patterns = [
            r'Á¨¨\d+Á´†',  # Á¨¨1Á´†, Á¨¨123Á´† –∏ —Ç.–¥.
            r'Á¨¨\d+Âõû',  # Á¨¨1Âõû, Á¨¨123Âõû –∏ —Ç.–¥.
            r'Chapter \d+',  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
            r'Ch\.\d+',  # –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç
        ]
        
        import re
        for pattern in story_patterns:
            if re.search(pattern, title):
                return True
        
        return False
    
    def get_chapter_content(self, chapter_url: str) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
        """
        html_content = self._get_page_content(chapter_url, description="–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã")
        
        if not html_content:
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã: {chapter_url}")
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã
            title_selectors = [
                'h2.title',
                '.title',
                'h1.chapter__title',
                'h1',
                'h2'
            ]
            
            title = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≥–ª–∞–≤–∞"
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    if title and len(title) > 5:
                        break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º chapter_id
            chapter_id = self._extract_chapter_id(chapter_url)
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            content_selectors = [
                'main[data-type="cjk"]',
                'main.content',
                '#reader-content main',
                'main',
                '.content'
            ]
            
            content_elem = None
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    break
                    
            if not content_elem:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            is_locked = "lock-mask" in str(content_elem)
            
            # –ï—Å–ª–∏ –≥–ª–∞–≤–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –°–ù–ê–ß–ê–õ–ê –ø—Ä–æ–±—É–µ–º —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É
            if is_locked:
                print(f"   üîí –ì–ª–∞–≤–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ (lock-mask) - –ø—Ä–æ–±—É–µ–º —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É...")
                
                # –ò—â–µ–º –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ JSON
                encrypted_content = self._extract_encrypted_content(html_content)
                
                if encrypted_content:
                    print(f"   üîê –ù–∞–π–¥–µ–Ω –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {len(encrypted_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
                    decrypted_text = self._decrypt_qidian_content(encrypted_content)
                    
                    if decrypted_text and len(decrypted_text) > 500:
                        print(f"   ‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω –ø—Ä–æ—Å—Ç—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º: {len(decrypted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return {
                            'title': title,
                            'content': decrypted_text,
                            'chapter_id': chapter_id,
                            'word_count': len(decrypted_text),
                            'is_locked': False,
                            'is_decrypted': True
                        }
                    else:
                        print(f"   ‚ö†Ô∏è –ü—Ä–æ—Å—Ç–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º Selenium...")
                        
                        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º Selenium –¥–ª—è JavaScript —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
                        if selenium_available and self.auth_cookies:
                            selenium_result = self._decrypt_with_selenium(chapter_url)
                            if selenium_result and len(selenium_result) > 500:
                                print(f"   ‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ Selenium: {len(selenium_result)} —Å–∏–º–≤–æ–ª–æ–≤")
                                return {
                                    'title': title,
                                    'content': selenium_result,
                                    'chapter_id': chapter_id,
                                    'word_count': len(selenium_result),
                                    'is_locked': False,
                                    'is_decrypted': True
                                }
                        
                        print(f"   ‚ùå –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
                else:
                    print(f"   ‚ùå –ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                # –ï—Å–ª–∏ –≥–ª–∞–≤–∞ –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                encrypted_content = self._extract_encrypted_content(html_content)
                if encrypted_content:
                    print(f"   üîê –ù–∞–π–¥–µ–Ω –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–Ω–µ–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–ª–∞–≤–∞): {len(encrypted_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
                    decrypted_text = self._decrypt_qidian_content(encrypted_content)
                    if decrypted_text and len(decrypted_text) > 500:
                        print(f"   ‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω –ø—Ä–æ—Å—Ç—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º: {len(decrypted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return {
                            'title': title,
                            'content': decrypted_text,
                            'chapter_id': chapter_id,
                            'word_count': len(decrypted_text),
                            'is_locked': False,
                            'is_decrypted': True
                        }
                    else:
                        print(f"   ‚ö†Ô∏è –ü—Ä–æ—Å—Ç–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º Selenium...")
                        
                        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º Selenium –¥–ª—è JavaScript —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
                        if selenium_available and self.auth_cookies:
                            selenium_result = self._decrypt_with_selenium(chapter_url)
                            if selenium_result and len(selenium_result) > 500:
                                # –û—á–∏—â–∞–µ–º Selenium —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç –ª–∏—à–Ω–µ–≥–æ
                                cleaned_result = self._clean_selenium_result(selenium_result)
                                print(f"   ‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ Selenium: {len(cleaned_result)} —Å–∏–º–≤–æ–ª–æ–≤")
                                return {
                                    'title': title,
                                    'content': cleaned_result,
                                    'chapter_id': chapter_id,
                                    'word_count': len(cleaned_result),
                                    'is_locked': False,
                                    'is_decrypted': True
                                }
                        
                        print(f"   ‚ùå Selenium —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
            
            # –û–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–µ—Å–ª–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å –∏–ª–∏ –Ω–µ –Ω—É–∂–Ω–∞)
            content = self._clean_chapter_content(content_elem)
            
            # –ï—Å–ª–∏ –≥–ª–∞–≤–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –º–∞–ª–æ, –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—É—é
            if is_locked and len(content) < 200:
                print(f"   üîí –ì–ª–∞–≤–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø–æ–ª—É—á–µ–Ω–æ –ø—Ä–µ–≤—å—é: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                content = f"[–ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù–ê] {content}"
            
            return {
                'title': title,
                'content': content,
                'chapter_id': chapter_id,
                'word_count': len(content),
                'is_locked': is_locked,
                'is_decrypted': False
            }
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≥–ª–∞–≤—ã: {e}")
            return {
                'title': '–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞—è –≥–ª–∞–≤–∞',
                'content': '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Å–∞–π—Ç–∞.',
                'chapter_id': self._extract_chapter_id(chapter_url) or '0',
                'word_count': 0,
                'is_locked': True,
                'is_decrypted': False
            }
    
    def _delay_between_requests(self):
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è Qidian
        """
        # –ë–∞–∑–æ–≤–∞—è –ø–∞—É–∑–∞
        base_delay = 2.0  # –£–≤–µ–ª–∏—á–∏–ª–∏ –±–∞–∑–æ–≤—É—é –ø–∞—É–∑—É
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        if self.consecutive_errors > 0:
            # –ë–æ–ª—å—à–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            base_delay *= (1 + self.consecutive_errors * 1.0)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–Ω–æ–∂–∏—Ç–µ–ª—å
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ 60 —Å–µ–∫—É–Ω–¥
        base_delay = min(base_delay, 60.0)
        
        # –°–ª—É—á–∞–π–Ω–∞—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞
        random_factor = random.uniform(0.5, 1.5)  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
        delay = base_delay + random_factor
        
        print(f"‚è≥ –ü–∞—É–∑–∞ {delay:.1f}s (–æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥: {self.consecutive_errors})...")
        time.sleep(delay)
    
    def _get_page_content(self, url: str, timeout: int = 10, description: str = "") -> Optional[str]:
        """
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Qidian
        """
        try:
            self.request_count += 1
            
            if description:
                print(f"üåê {description}: {url}")
            else:
                print(f"üåê –ó–∞–ø—Ä–æ—Å: {url}")
            
            response = self.session.get(url, timeout=timeout)
            
            print(f"   –°—Ç–∞—Ç—É—Å: {response.status_code}")
            print(f"   –†–∞–∑–º–µ—Ä: {len(response.content):,} –±–∞–π—Ç")
            
            if response.status_code == 200:
                html_content = response.text
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ HTML –¥–ª—è Qidian
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ HTML
                is_valid_html = (
                    html_content and 
                    len(html_content) > 1000 and  # –£–º–µ–Ω—å—à–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    html_content.strip().startswith('<')
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Qidian –º–∞—Ä–∫–µ—Ä—ã
                has_qidian_markers = (
                    'Ëµ∑ÁÇπ‰∏≠ÊñáÁΩë' in html_content or 
                    'qidian.com' in html_content or
                    'reader-content' in html_content or
                    'chapter' in html_content.lower()
                )
                
                if is_valid_html and has_qidian_markers:
                    self.success_count += 1
                    self.consecutive_errors = 0
                    print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π HTML –ø–æ–ª—É—á–µ–Ω ({len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return html_content
                else:
                    print("‚ö†Ô∏è HTML –Ω–µ –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞")
                    print(f"   –†–∞–∑–º–µ—Ä: {len(html_content)}, HTML: {is_valid_html}, Qidian: {has_qidian_markers}")
                    self.consecutive_errors += 1
                    
            elif response.status_code == 202:
                print("‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 202 - –≤–æ–∑–º–æ–∂–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –±–æ—Ç–æ–≤")
                self.consecutive_errors += 1
                time.sleep(5)
                
            elif response.status_code == 403:
                print("‚ö†Ô∏è HTTP 403 Forbidden - –∑–∞—â–∏—Ç–∞ –æ—Ç –±–æ—Ç–æ–≤")
                self.consecutive_errors += 1
                
                # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º User-Agent –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö 403
                self._rotate_user_agent()
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –ø—Ä–∏ 403 –æ—à–∏–±–∫–µ
                delay = 15 + (self.consecutive_errors * 5)  # –ú–∏–Ω–∏–º—É–º 15 —Å–µ–∫, +5 —Å–µ–∫ –∑–∞ –∫–∞–∂–¥—É—é –æ—à–∏–±–∫—É
                print(f"‚è≥ –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –ø–∞—É–∑–∞: {delay} —Å–µ–∫—É–Ω–¥...")
                time.sleep(delay)
                
            elif response.status_code == 429:
                print("‚ö†Ô∏è Rate limiting - —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤")
                self.consecutive_errors += 1
                time.sleep(10)
                
            else:
                print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {response.status_code}")
                self.consecutive_errors += 1
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {url}: {e}")
            self.consecutive_errors += 1
            
        return None
    
    def _extract_book_id(self, book_url: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å ID –∫–Ω–∏–≥–∏ –∏–∑ URL
        """
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã URL
        patterns = [
            r'/book/(\d+)/?',
            r'qidian\.com/book/(\d+)',
            r'm\.qidian\.com/book/(\d+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, book_url)
            if match:
                return match.group(1)
        
        return None
    
    def _extract_chapter_id(self, chapter_url: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å ID –≥–ª–∞–≤—ã –∏–∑ URL
        """
        match = re.search(r'/chapter/\d+/(\d+)/?', chapter_url)
        return match.group(1) if match else None
    
    def _extract_title(self, soup: BeautifulSoup) -> str:
        """
        –ò–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
        """
        # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–Ω–∏–≥–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ h1
        title_elem = soup.select_one('h1')
        if title_elem:
            title = title_elem.get_text(strip=True)
            if title and title != 'ÁÆÄ‰ªã' and title != 'ÁõÆÂΩï':  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                return title
        
        # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        selectors = [
            '[class*="title"]',
            '.title',
            '.book-name',
            '.book__name'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                title = elem.get_text(strip=True)
                if title and len(title) > 2 and title not in ['ÁÆÄ‰ªã', 'ÁõÆÂΩï']:
                    return title
        
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _extract_author(self, soup: BeautifulSoup) -> str:
        """
        –ò–∑–≤–ª–µ—á—å –∞–≤—Ç–æ—Ä–∞ –∫–Ω–∏–≥–∏
        """
        # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–æ–¥–µ—Ä–∂–∞—â–∏–º "author"
        author_elements = soup.select('[class*="author"]')
        for elem in author_elements:
            text = elem.get_text(strip=True)
            if text and len(text) > 1 and len(text) < 50:  # –†–∞–∑—É–º–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞
                return text
        
        # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        selectors = [
            '.book__author',
            '.book-author',
            '.author',
            '.book-info__author',
            '.writer',
            '.book-writer'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                return elem.get_text(strip=True)
        
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _extract_status(self, soup: BeautifulSoup) -> str:
        """
        –ò–∑–≤–ª–µ—á—å —Å—Ç–∞—Ç—É—Å –∫–Ω–∏–≥–∏
        """
        selectors = [
            '.book__status',
            '.book-status',
            '.status'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                return elem.get_text(strip=True)
        
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _extract_genre(self, soup: BeautifulSoup) -> str:
        """
        –ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä –∫–Ω–∏–≥–∏
        """
        selectors = [
            '.book__genre',
            '.book-genre',
            '.genre',
            '.tag'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                return elem.get_text(strip=True)
        
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _extract_description(self, soup: BeautifulSoup) -> str:
        """
        –ò–∑–≤–ª–µ—á—å –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
        """
        selectors = [
            '.book__desc',
            '.book-description',
            '.description',
            '.book-intro'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                return elem.get_text(strip=True)
        
        return "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è"
    
    def _clean_chapter_content(self, content_elem) -> str:
        """
        –û—á–∏—Å—Ç–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã –æ—Ç –ª–∏—à–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        """
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
        unwanted_selectors = [
            'script', 'style', '.ad', '.advertisement', '.nav', '.navigation',
            '.header', '.footer', '.sidebar', '.comment', '.share', '.social',
            '.related', '.recommend', '[class*="ad"]', '[class*="banner"]',
            '.download-bar', '.icon-container', '.y-button', '.auto-tr'
        ]
        
        for selector in unwanted_selectors:
            for unwanted in content_elem.select(selector):
                unwanted.decompose()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        paragraphs = []
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for p in content_elem.find_all('p'):
            text = p.get_text(strip=True)
            if text and len(text) > 10:  # –£–º–µ–Ω—å—à–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
                text = text.lstrip('„ÄÄ')  # –£–±–∏—Ä–∞–µ–º –∫–∏—Ç–∞–π—Å–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã
                if text and len(text) > 10:
                    paragraphs.append(text)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, –∏—â–µ–º –≤ div'–∞—Ö
        if not paragraphs:
            for div in content_elem.find_all('div'):
                text = div.get_text(strip=True)
                if text and len(text) > 20:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –Ω–∞–≤–∏–≥–∞—Ü–∏—è
                    if not any(nav_word in text.lower() for nav_word in ['ÁõÆÂΩï', '‰∏ã‰∏ÄÁ´†', '‰∏ä‰∏ÄÁ´†', 'menu', 'next', 'prev', 'app', '‰∏ãËΩΩ']):
                        paragraphs.append(text)
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç–æ, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        if not paragraphs:
            full_text = content_elem.get_text(strip=True)
            if full_text:
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
                lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                paragraphs = [line for line in lines if len(line) > 10]
        
        result = '\n\n'.join(paragraphs) if paragraphs else "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if len(result) > 50:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–ª–∞–¥–∫—É —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø—É—Å—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            print(f"   üìù –û—á–∏—â–µ–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {len(paragraphs)} –∞–±–∑–∞—Ü–µ–≤, {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return result
    
    def _extract_encrypted_content(self, html_content: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        try:
            # –ò—â–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è Qidian JSON –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            patterns = [
                # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω - content –ø–æ–ª–µ —Å –¥–ª–∏–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
                (r'"content"\s*:\s*"([^"]{1000,})"', "content field"),
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                (r'"chapterContent"\s*:\s*"([^"]{1000,})"', "chapterContent field"),
                (r'"text"\s*:\s*"([^"]{1000,})"', "text field"),
                (r'window\.__INITIAL_STATE__\s*=\s*({.+?});', "INITIAL_STATE"),
                (r'window\.g_data\s*=\s*({.+?});', "g_data")
            ]
            
            for pattern, name in patterns:
                matches = re.findall(pattern, html_content, re.DOTALL)
                for match in matches:
                    try:
                        if match.startswith('{'):
                            # JSON –æ–±—ä–µ–∫—Ç
                            data = json.loads(match)
                            content = self._find_encrypted_in_json(data)
                            if content:
                                print(f"   üéØ –ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω –≤ {name}")
                                return content
                        elif len(match) > 1000:
                            # –î–ª–∏–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ - –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                            if self._looks_like_base64(match):
                                print(f"   üéØ –ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω –≤ {name} (–ø—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)")
                                return match
                    except json.JSONDecodeError:
                        continue
            
            print(f"   ‚ùå –ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö")
            return None
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return None
    
    def _find_encrypted_in_json(self, data, visited=None) -> str:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON
        """
        if visited is None:
            visited = set()
        
        if id(data) in visited:
            return None
        visited.add(id(data))
        
        try:
            if isinstance(data, dict):
                # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
                content_keys = ['content', 'chapterContent', 'text', 'body', 'data']
                for key in content_keys:
                    if key in data and isinstance(data[key], str) and len(data[key]) > 1000:
                        return data[key]
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
                for value in data.values():
                    result = self._find_encrypted_in_json(value, visited)
                    if result:
                        return result
                        
            elif isinstance(data, list):
                for item in data:
                    result = self._find_encrypted_in_json(item, visited)
                    if result:
                        return result
            
            elif isinstance(data, str) and len(data) > 1000:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–µ –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ base64
                if self._looks_like_base64(data):
                    return data
            
            return None
            
        except Exception:
            return None
    
    def _looks_like_base64(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂ –ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ base64
        """
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Ç–æ–ª—å–∫–æ base64 —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
        base64_chars = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=')
        return (
            len(text) > 100 and
            len(text) % 4 == 0 and  # Base64 –≤—Å–µ–≥–¥–∞ –∫—Ä–∞—Ç–Ω–æ 4
            all(c in base64_chars for c in text) and
            text.count('=') <= 2  # –ú–∞–∫—Å–∏–º—É–º 2 –∑–Ω–∞–∫–∞ padding
        )
    
    def _decrypt_qidian_content(self, encrypted_content: str) -> str:
        """
        –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ Qidian —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
        """
        # –ê–ª–≥–æ—Ä–∏—Ç–º—ã —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        decryption_methods = [
            ('zGup5_xor', self._decrypt_with_key, 'zGup5'),
            ('qidian_xor', self._decrypt_with_key, 'qidian'),
            ('reader_xor', self._decrypt_with_key, 'reader'),
            ('zGup5_zlib', self._decrypt_with_zlib, 'zGup5'),
            ('qidian_zlib', self._decrypt_with_zlib, 'qidian')
        ]
        
        for method_name, method_func, key in decryption_methods:
            try:
                result = method_func(encrypted_content, key)
                if result and self._is_valid_chinese_text(result):
                    print(f"   ‚úÖ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —É—Å–ø–µ—à–Ω–∞ –º–µ—Ç–æ–¥–æ–º: {method_name}")
                    return result
            except Exception as e:
                continue
        
        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç")
        return None
    
    def _decrypt_with_key(self, encrypted_content: str, key: str) -> str:
        """
        –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Å –ø–æ–º–æ—â—å—é XOR –∫–ª—é—á–∞
        """
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
            decoded = base64.b64decode(encrypted_content)
            
            # XOR –¥–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
            key_bytes = key.encode('utf-8')
            xored = bytes(decoded[i] ^ key_bytes[i % len(key_bytes)] for i in range(len(decoded)))
            
            # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å UTF-8
            return xored.decode('utf-8')
            
        except Exception:
            return None
    
    def _decrypt_with_zlib(self, encrypted_content: str, key: str) -> str:
        """
        –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Å –ø–æ–º–æ—â—å—é XOR + zlib –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–∏
        """
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
            decoded = base64.b64decode(encrypted_content)
            
            # XOR –¥–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
            key_bytes = key.encode('utf-8')
            xored = bytes(decoded[i] ^ key_bytes[i % len(key_bytes)] for i in range(len(decoded)))
            
            # –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—è zlib
            decompressed = zlib.decompress(xored)
            
            # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å UTF-8
            return decompressed.decode('utf-8')
            
        except Exception:
            return None
    
    def _is_valid_chinese_text(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–∏—Ç–∞–π—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º
        """
        if not text or len(text) < 100:
            return False
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        chinese_ratio = chinese_chars / len(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–ª–∞–≤—ã)
        keywords_found = any(keyword in text for keyword in ['ÊâøËØ∫', 'ÂÆåÁæé', 'ÊàëÂ∏¶', 'Â≠üÊòä'])
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        return (
            chinese_ratio > 0.15 or  # –ú–∏–Ω–∏–º—É–º 15% –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            keywords_found or  # –ù–∞–π–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            chinese_chars > 500  # –ú–∏–Ω–∏–º—É–º 500 –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        )
    
    def _decrypt_with_selenium(self, chapter_url: str) -> str:
        """
        –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é Selenium (JavaScript –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)
        """
        if not selenium_available:
            print(f"   ‚ùå Selenium –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return None
        
        try:
            print(f"   üåê –ó–∞–ø—É—Å–∫ Selenium –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏...")
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Chrome
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1')
            chrome_options.binary_location = "/usr/bin/chromium-browser"
            
            # –î–æ–±–∞–≤–ª—è–µ–º SOCKS –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
            if self.socks_proxy:
                chrome_options.add_argument(f'--proxy-server=socks5://{self.socks_proxy}')
                chrome_options.add_argument('--host-resolver-rules="MAP * 0.0.0.0 , EXCLUDE localhost"')
                print(f"   üåê Selenium –∏—Å–ø–æ–ª—å–∑—É–µ—Ç SOCKS –ø—Ä–æ–∫—Å–∏: {self.socks_proxy}")
            
            service = Service('/usr/bin/chromedriver')
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ cookies
            driver.get("https://m.qidian.com/")
            time.sleep(2)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cookies
            if self.auth_cookies:
                cookies_set = 0
                for cookie_pair in self.auth_cookies.split(';'):
                    if '=' in cookie_pair:
                        name, value = cookie_pair.strip().split('=', 1)
                        try:
                            driver.add_cookie({
                                'name': name.strip(),
                                'value': value.strip(),
                                'domain': '.qidian.com'
                            })
                            cookies_set += 1
                        except:
                            pass
                print(f"   üç™ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ cookies: {cookies_set}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≥–ª–∞–≤—ã
            driver.get(chapter_url)
            
            # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è JavaScript
            wait_times = [5, 10, 15]
            for wait_time in wait_times:
                time.sleep(wait_time)
                print(f"   ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ JavaScript –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {wait_time} —Å–µ–∫—É–Ω–¥...")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                js_extractors = [
                    # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                    "return document.querySelector('main') ? document.querySelector('main').innerText : '';",
                    # –í—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                    "return Array.from(document.querySelectorAll('p')).map(p => p.innerText).join('\\n');",
                    # –í–µ—Å—å body
                    "return document.body.innerText;",
                    # –ö–∏—Ç–∞–π—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                    "var allText = document.documentElement.innerText; var lines = allText.split('\\n'); var chineseLines = []; for (var i = 0; i < lines.length; i++) { var line = lines[i].trim(); if (line.length > 10) { var chineseCount = (line.match(/[\\u4e00-\\u9fff]/g) || []).length; if (chineseCount > 5) { chineseLines.push(line); } } } return chineseLines.join('\\n');",
                    # –ü–æ–∏—Å–∫ –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
                    "var elements = document.querySelectorAll('div, section, article'); var texts = []; for (var i = 0; i < elements.length; i++) { var text = elements[i].innerText; if (text && text.length > 100) { var chineseCount = (text.match(/[\\u4e00-\\u9fff]/g) || []).length; if (chineseCount > 50) { texts.push(text); } } } return texts.join('\\n');"
                ]
                
                for i, js_code in enumerate(js_extractors):
                    try:
                        result = driver.execute_script(js_code)
                        if result and len(result.strip()) > 500:
                            chinese_chars = sum(1 for char in result if '\u4e00' <= char <= '\u9fff')
                            print(f"   üìä –ú–µ—Ç–æ–¥ {i+1} (–æ–∂–∏–¥–∞–Ω–∏–µ {wait_time}s): {len(result)} —Å–∏–º–≤–æ–ª–æ–≤, {chinese_chars} –∫–∏—Ç–∞–π—Å–∫–∏—Ö")
                            
                            if chinese_chars > 200:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                                print(f"   ‚úÖ Selenium –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
                                driver.quit()
                                return result
                    except Exception as e:
                        continue
                
                # –ï—Å–ª–∏ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –Ω–∞—à–ª–∏ —á—Ç–æ-—Ç–æ, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ, –∑–∞–ø–æ–º–∏–Ω–∞–µ–º
                print(f"   ‚è≥ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ... (—ç—Ç–∞–ø {wait_time}s –∑–∞–≤–µ—Ä—à–µ–Ω)")
            
            driver.quit()
            print(f"   ‚ùå Selenium –Ω–µ —Å–º–æ–≥ –∏–∑–≤–ª–µ—á—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
            return None
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ Selenium: {e}")
            try:
                driver.quit()
            except:
                pass
            return None
    
    def _clean_selenium_result(self, selenium_text: str) -> str:
        """
        –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç Selenium –æ—Ç –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ —Å–ª—É–∂–µ–±–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        if not selenium_text:
            return ""
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines = selenium_text.split('\n')
        
        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –æ—á–µ–≤–∏–¥–Ω—ã–µ)
        excluded_keywords = [
            'ËèúÂçï', 'Á´†ËäÇÂä†ËΩΩÂ§±Ë¥•', '‰∏çÂÜçÊòæÁ§∫ËÆ¢ÈòÖÊèêÈÜí', 'APPÁúãÂπøÂëäÂÖçË¥πËß£ÈîÅ',
            'ËÆ¢ÈòÖÊú¨Á´†', 'ÊâπÈáèËÆ¢ÈòÖ', '‰∏ã‰∏ÄÁ´†'
        ]
        
        cleaned_lines = []
        seen_content = set()  # –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            is_service_line = False
            for keyword in excluded_keywords:
                if keyword in line:
                    is_service_line = True
                    break
            
            if is_service_line:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç)
            if len(line) > 20:
                if line in seen_content:
                    continue
                seen_content.add(line)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º (–º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä)
            if len(line) > 3:
                cleaned_lines.append(line)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Ç–µ–∫—Å—Ç
        result = '\n\n'.join(cleaned_lines)
        
        # –ú—è–≥–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ - —É–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏
        # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã
        title_pattern = r'Á¨¨‰∫åÂç∑ ÂàùÂÖ•ÂçóÂüü Á¨¨131Á´† ÊàëÂ∏¶ÊâøËØ∫ËÄåÊù•ÔºÅ'
        title_matches = re.findall(title_pattern, result)
        if len(title_matches) > 1:
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
            result = re.sub(title_pattern, '', result)
            result = title_pattern + '\n\n' + result.strip()
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–∞–º–∏ —Ç–æ—á–µ–∫ –∏ –±–∞–ª–∞–Ω—Å–∞
        result = re.sub(r'^\d+ÁÇπ$', '', result, flags=re.MULTILINE)
        result = re.sub(r'^‰ΩôÈ¢ù\d+ÁÇπ$', '', result, flags=re.MULTILINE)
        
        # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        result = re.sub(r'\n{3,}', '\n\n', result)
        
        return result.strip()


def main():
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞ Qidian
    """
    print("üìö QIDIAN PARSER - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤–∞—è –∫–Ω–∏–≥–∞
    book_url = "https://www.qidian.com/book/1209977/"  # ÊñóÁ†¥ËãçÁ©π
    
    with QidianParser() as parser:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–Ω–∏–≥–µ
            print("üìñ –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–Ω–∏–≥–µ...")
            book_info = parser.get_book_info(book_url)
            print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {book_info['title']}")
            print(f"‚úÖ –ê–≤—Ç–æ—Ä: {book_info['author']}")
            print(f"‚úÖ –ñ–∞–Ω—Ä: {book_info['genre']}")
            print()
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∫–Ω–∏–≥—É (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 3 –≥–ª–∞–≤–∞–º–∏ –¥–ª—è –¥–µ–º–æ)
            print("üìö –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏...")
            results = parser.download_book(book_url, "./qidian_parsed", chapter_limit=3)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = parser.get_stats()
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}")
            print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {stats['successful_requests']}")
            print(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats['success_rate']:.1%}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()