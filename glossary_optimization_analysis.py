#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è ISSTH –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —É–¥–∞–ª–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º
"""

import json
import re
from typing import Dict, List, Tuple, Set
from collections import defaultdict

def load_glossary(file_path: str) -> Dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–æ—Å—Å–∞—Ä–∏—è –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def is_direct_translation(chinese: str, russian: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º (–ø—Ä—è–º—ã–º)
    –ö—Ä–∏—Ç–µ—Ä–∏–∏:
    1. –ö–æ—Ä–æ—Ç–∫–∏–µ –æ–±—â–µ—É–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–≥–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å –∏ —Ç.–¥.)
    2. –ú–µ–∂–¥–æ–º–µ—Ç–∏—è –∏ –∑–≤—É–∫–æ–ø–æ–¥—Ä–∞–∂–∞–Ω–∏—è
    3. –ß–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    4. –ü—Ä–æ—Å—Ç—ã–µ —Ü–≤–µ—Ç–∞
    5. –ë–∞–∑–æ–≤—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
    """
    
    # –ü—Ä–æ—Å—Ç—ã–µ –æ–±—â–µ—É–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
    direct_translations = {
        'Âπ¥': '–≥–æ–¥',
        'Êúà': '–º–µ—Å—è—Ü',
        'Êó•': '–¥–µ–Ω—å',
        'Â§©': '–Ω–µ–±–æ',
        'Âú∞': '–∑–µ–º–ª—è',
        'Ê∞¥': '–≤–æ–¥–∞',
        'ÁÅ´': '–æ–≥–æ–Ω—å',
        'È£é': '–≤–µ—Ç–µ—Ä',
        'Â±±': '–≥–æ—Ä–∞',
        '‰∫∫': '—á–µ–ª–æ–≤–µ–∫',
        'ÂøÉ': '—Å–µ—Ä–¥—Ü–µ',
        'Êâã': '—Ä—É–∫–∞',
        'Â§¥': '–≥–æ–ª–æ–≤–∞',
        'Áúº': '–≥–ª–∞–∑',
        'Âè£': '—Ä–æ—Ç'
    }
    
    # –ó–≤—É–∫–æ–ø–æ–¥—Ä–∞–∂–∞–Ω–∏—è –∏ –º–µ–∂–¥–æ–º–µ—Ç–∏—è - –≤—Å–µ–≥–¥–∞ –ø—Ä—è–º–æ–π –ø–µ—Ä–µ–≤–æ–¥
    sound_patterns = [
        r'^[ÂïäÂìàÂëµÂóØÂí≥ËΩ∞Á†∞Âó°ÂíîÂôóÂìºÂîâÂì¶ÂëÉ]+',
        r'^(—Ö–∞|—Ö–µ|–º–º|—Ö–º|–∫—Ö–µ|–±—É–º|–±–∞—Ö|–ø—É—Ö|—Ñ—ã—Ä–∫)'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–≤—É–∫–æ–ø–æ–¥—Ä–∞–∂–∞–Ω–∏—è
    for pattern in sound_patterns:
        if re.match(pattern, chinese) or re.match(pattern, russian, re.IGNORECASE):
            return True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ —Ü–≤–µ—Ç–∞ (–±–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)
    basic_colors = {
        'Á∫¢': '–∫—Ä–∞—Å–Ω—ã–π',
        'Ëìù': '—Å–∏–Ω–∏–π',
        'Áªø': '–∑–µ–ª—ë–Ω—ã–π',
        'ÈªÑ': '–∂—ë–ª—Ç—ã–π',
        'ÁôΩ': '–±–µ–ª—ã–π',
        'Èªë': '—á—ë—Ä–Ω—ã–π'
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä—è–º—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    if chinese in direct_translations:
        return True
    
    if chinese in basic_colors and basic_colors[chinese].lower() in russian.lower():
        return True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–µ–ª
    if chinese.isdigit() or russian.isdigit():
        return True
    
    return False

def is_cultivation_specific_term(chinese: str, russian: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ—Ä–º–∏–Ω —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º –¥–ª—è –∫—É–ª—å—Ç–∏–≤–∞—Ü–∏–∏
    –¢–∞–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω—É–∂–Ω–æ –°–û–•–†–ê–ù–ò–¢–¨ –≤ –≥–ª–æ—Å—Å–∞—Ä–∏–∏
    """
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫—É–ª—å—Ç–∏–≤–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
    cultivation_keywords = [
        '–∫—É–ª—å—Ç–∏–≤–∞—Ü', '—Ü–∏', '–¥–∞–æ', '–¥—É—à', '—è–¥—Ä', '–º–µ—Ä–∏–¥–∏–∞–Ω', 
        '–¥–∞–Ω—å—Ç—è–Ω—å', '–ø–∏–ª—é–ª', '–∞–ª—Ö–∏–º', '–∞—Ä—Ç–µ—Ñ–∞–∫—Ç', '—Å–æ–∫—Ä–æ–≤–∏—â',
        '—Ç–µ—Ö–Ω–∏–∫', '–∑–∞–∫–ª–∏–Ω–∞–Ω', '—Å–µ–∫—Ç–∞', '—Å—Ç–∞—Ä–µ–π—à–∏–Ω', '–ø–µ—á–∞—Ç',
        '–±–µ—Å—Å–º–µ—Ä—Ç', '–Ω–µ–±–µ—Å–Ω', '–±–æ–∂–µ—Å—Ç–≤–µ–Ω', '–¥—É—Ö–æ–≤–Ω', '–∫–∞—Ä–º'
    ]
    
    russian_lower = russian.lower()
    for keyword in cultivation_keywords:
        if keyword in russian_lower:
            return True
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–∏—Ç–∞–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∫—É–ª—å—Ç–∏–≤–∞—Ü–∏–∏
    cultivation_chinese = [
        '‰øÆ', 'ÁÇº', '‰ªô', 'ÈÅì', 'Ê∞î', '‰∏π', 'ÁÅµ', 'Á•û', 
        'ÂÖÉ', 'Áúü', 'Ê≥ï', 'ÂÆù', 'ÊúØ', 'Âäü', 'ËÑâ', 'ÂÆó'
    ]
    
    for char in cultivation_chinese:
        if char in chinese:
            return True
    
    return False

def analyze_glossary(glossary: Dict) -> Tuple[Dict, Dict]:
    """
    –ê–Ω–∞–ª–∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞:
    1. –¢–µ—Ä–º–∏–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥)
    2. –¢–µ—Ä–º–∏–Ω—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫—É–ª—å—Ç–∏–≤–∞—Ü–∏–∏)
    """
    
    terms_to_remove = defaultdict(dict)
    terms_to_keep = defaultdict(dict)
    
    for category, terms in glossary.items():
        if category in ['novel_info', 'description', 'title']:
            continue
            
        for chinese, russian in (terms.items() if isinstance(terms, dict) else []):
            if is_direct_translation(chinese, russian):
                terms_to_remove[category][chinese] = russian
            elif is_cultivation_specific_term(chinese, russian):
                terms_to_keep[category][chinese] = russian
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Ä–º–∏–Ω, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω—ã
                terms_to_keep[category][chinese] = russian
    
    return dict(terms_to_remove), dict(terms_to_keep)

def create_optimized_glossary(original_glossary: Dict, terms_to_keep: Dict) -> Dict:
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
    
    optimized = {}
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    if 'novel_info' in original_glossary:
        optimized['novel_info'] = original_glossary['novel_info']
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
    for category, terms in terms_to_keep.items():
        if terms:  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Ä–º–∏–Ω—ã
            optimized[category] = terms
    
    return optimized

def generate_report(terms_to_remove: Dict, terms_to_keep: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    
    report = []
    report.append("=" * 80)
    report.append("–û–¢–ß–ï–¢ –û–ë –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ì–õ–û–°–°–ê–†–ò–Ø ISSTH")
    report.append("=" * 80)
    report.append("")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_removed = sum(len(terms) for terms in terms_to_remove.values())
    total_kept = sum(len(terms) for terms in terms_to_keep.values())
    total = total_removed + total_kept
    
    report.append(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {total}")
    report.append(f"–¢–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {total_removed} ({total_removed/total*100:.1f}%)")
    report.append(f"–¢–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {total_kept} ({total_kept/total*100:.1f}%)")
    report.append("")
    
    # –¢–µ—Ä–º–∏–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    report.append("-" * 40)
    report.append("–¢–ï–†–ú–ò–ù–´ –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø (–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥):")
    report.append("-" * 40)
    
    for category, terms in terms_to_remove.items():
        if terms:
            report.append(f"\n{category.upper()}:")
            for chinese, russian in sorted(terms.items()):
                report.append(f"  {chinese} ‚Üí {russian}")
    
    # –¢–µ—Ä–º–∏–Ω—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø—Ä–∏–º–µ—Ä—ã)
    report.append("\n" + "-" * 40)
    report.append("–ü–†–ò–ú–ï–†–´ –°–û–•–†–ê–ù–ï–ù–ù–´–• –¢–ï–†–ú–ò–ù–û–í (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫—É–ª—å—Ç–∏–≤–∞—Ü–∏–∏):")
    report.append("-" * 40)
    
    examples_shown = 0
    for category, terms in terms_to_keep.items():
        if terms and examples_shown < 20:
            report.append(f"\n{category.upper()} (–ø—Ä–∏–º–µ—Ä—ã):")
            for chinese, russian in list(terms.items())[:5]:
                report.append(f"  {chinese} ‚Üí {russian}")
                examples_shown += 1
    
    return "\n".join(report)

def main():
    # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–æ—Å—Å–∞—Ä–∏–µ–≤...")
    
    glossary1 = load_glossary('/home/user/novelbins-epub/issth_glossary_chinese.json')
    glossary2 = load_glossary('/home/user/novelbins-epub/translation_templates/issth_glossary.json')
    
    print("\n–ê–Ω–∞–ª–∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è issth_glossary_chinese.json...")
    remove1, keep1 = analyze_glossary(glossary1)
    
    print("–ê–Ω–∞–ª–∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è issth_glossary.json...")
    remove2, keep2 = analyze_glossary(glossary2)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
    report1 = generate_report(remove1, keep1)
    report2 = generate_report(remove2, keep2)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
    with open('/home/user/novelbins-epub/glossary_optimization_report.txt', 'w', encoding='utf-8') as f:
        f.write("–ê–ù–ê–õ–ò–ó –§–ê–ô–õ–ê: issth_glossary_chinese.json\n")
        f.write(report1)
        f.write("\n\n")
        f.write("–ê–ù–ê–õ–ò–ó –§–ê–ô–õ–ê: translation_templates/issth_glossary.json\n")
        f.write(report2)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥–ª–æ—Å—Å–∞—Ä–∏–µ–≤
    optimized1 = create_optimized_glossary(glossary1, keep1)
    optimized2 = create_optimized_glossary(glossary2, keep2)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥–ª–æ—Å—Å–∞—Ä–∏–µ–≤
    with open('/home/user/novelbins-epub/issth_glossary_optimized.json', 'w', encoding='utf-8') as f:
        json.dump(optimized1, f, ensure_ascii=False, indent=2)
    
    with open('/home/user/novelbins-epub/translation_templates/issth_glossary_optimized.json', 'w', encoding='utf-8') as f:
        json.dump(optimized2, f, ensure_ascii=False, indent=2)
    
    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: glossary_optimization_report.txt")
    print(f"üìö –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–ª–æ—Å—Å–∞—Ä–∏–∏:")
    print(f"   - issth_glossary_optimized.json")
    print(f"   - translation_templates/issth_glossary_optimized.json")
    
    # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
    print(f"   –§–∞–π–ª 1: —É–¥–∞–ª–µ–Ω–æ {sum(len(t) for t in remove1.values())} —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ {sum(len(t) for t in glossary1.values()) if isinstance(glossary1, dict) else 0}")
    print(f"   –§–∞–π–ª 2: —É–¥–∞–ª–µ–Ω–æ {sum(len(t) for t in remove2.values())} —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ {sum(len(t) for t in glossary2.values()) if isinstance(glossary2, dict) else 0}")

if __name__ == '__main__':
    main()