#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–ª–∞–≤—ã 1276 - —Ç–æ–π, –∫–æ—Ç–æ—Ä—É—é —É–∫–∞–∑–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
"""
import time
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), 'parsers', 'sources'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'parsers', 'base'))

from czbooks_parser import CZBooksParser
from bs4 import BeautifulSoup

def test_specific_chapter():
    """–¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≥–ª–∞–≤—ã 1276"""

    test_url = "https://czbooks.net/n/ul6pe/ui23ko"  # –ì–ª–∞–≤–∞ 1276

    print("=" * 80)
    print(f"üß™ –¢–ï–°–¢ –ì–õ–ê–í–´ 1276")
    print("=" * 80)
    print(f"\nüìÑ URL: {test_url}\n")

    from dotenv import load_dotenv
    load_dotenv()

    auth_cookies = os.getenv('CZBOOKS_COOKIES', '')
    socks_proxy = os.getenv('PROXY_URL', '').replace('socks5://', '')

    parser = CZBooksParser(
        auth_cookies=auth_cookies,
        socks_proxy=socks_proxy,
        headless=False
    )

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        html = parser._get_page_with_selenium(test_url, wait_time=25)
        soup = BeautifulSoup(html, 'html.parser')

        print("\n" + "=" * 80)
        print("üìä –ê–ù–ê–õ–ò–ó –ö–û–ù–¢–ï–ù–¢–ê")
        print("=" * 80)

        # –ò—â–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä .content
        content_elem = soup.select_one('.content')

        if content_elem:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
            full_text = content_elem.get_text(separator='\n', strip=True)

            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç .content")
            print(f"   üìè –î–ª–∏–Ω–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   üìù –°—Ç—Ä–æ–∫: {len(full_text.split(chr(10)))}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º–∞—Ä–∫–µ—Ä—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            page_html = str(soup).lower()
            has_lock = any(word in page_html for word in ['lock', 'vip', 'subscribe', 'premium'])

            print(f"   üîí –ú–∞—Ä–∫–µ—Ä—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {'–î–ê' if has_lock else '–ù–ï–¢'}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü
            print(f"\n   üìÑ –ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(f"   {full_text[:200]}")

            print(f"\n   üìÑ –ö–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(f"   {full_text[-200:]}")

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Ç–µ–∫—Å—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_text_start = "„Ää‰∏ÄÂøµÊ∞∏ÊÅÜ„ÄãÁ¨¨‰∏ÄÂçÉ‰∫åÁôæ‰∏ÉÂçÅÂÖ≠Á´† ËòáÈÜíÔºÅ"
            user_text_fragment = "ËÇâË∫´Â§™Âè§ÔºÅ"

            if user_text_start in full_text:
                print(f"\n   ‚úÖ –ù–ê–ô–î–ï–ù –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è!")
            else:
                print(f"\n   ‚ùå –ù–ï –Ω–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {user_text_start}")

            if user_text_fragment in full_text:
                print(f"   ‚úÖ –ù–ê–ô–î–ï–ù —Ñ—Ä–∞–≥–º–µ–Ω—Ç '–ø–ª–æ—Ç—å –¥—Ä–µ–≤–Ω–æ—Å—Ç–∏' –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è!")
            else:
                print(f"   ‚ùå –ù–ï –Ω–∞–π–¥–µ–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—Ä—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            truncation_markers = ['UUÁúãÊõ∏', 'ÊâãÊ©üÁî®Êà∂', 'Ê≠°ËøéÂª£Â§ßÊõ∏Âèã']
            has_truncation = any(marker in full_text for marker in truncation_markers)

            if has_truncation:
                print(f"\n   ‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –º–∞—Ä–∫–µ—Ä—ã –æ–±—Ä—ã–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø—Ä–µ–≤—å—é)")
                print(f"   –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã")
            else:
                print(f"\n   ‚úÖ –ú–∞—Ä–∫–µ—Ä–æ–≤ –æ–±—Ä—ã–≤–∞–Ω–∏—è –ù–ï –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º: —ç—Ç–æ –ø—Ä–µ–≤—å—é –∏–ª–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç?
            if len(full_text) < 500:
                verdict = "‚ùå –°–õ–ò–®–ö–û–ú –ö–û–†–û–¢–ö–ò–ô - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–µ–≤—å—é"
            elif has_truncation:
                verdict = "‚ö†Ô∏è –ü–†–ï–í–¨–Æ - –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–∞—Ä–∫–µ—Ä—ã –æ–±—Ä—ã–≤–∞–Ω–∏—è"
            elif len(full_text) > 5000:
                verdict = "‚úÖ –ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –¥–ª–∏–Ω–∞"
            else:
                verdict = "‚ö†Ô∏è –ù–ï–Ø–°–ù–û - —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞, –Ω—É–∂–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞"

            print(f"\n" + "=" * 80)
            print(f"üéØ –í–ï–†–î–ò–ö–¢: {verdict}")
            print("=" * 80)

        else:
            print("\n‚ùå –≠–ª–µ–º–µ–Ω—Ç .content –ù–ï –ù–ê–ô–î–ï–ù!")

            # –ü–æ–∏—Å–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
            print("\nüîç –ü–æ–∏—Å–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤...")
            for selector in ['.chapter', '#content', 'article', 'main']:
                elem = soup.select_one(selector)
                if elem:
                    text = elem.get_text(strip=True)
                    print(f"   ‚úÖ {selector}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    finally:
        parser.close()

if __name__ == "__main__":
    test_specific_chapter()
