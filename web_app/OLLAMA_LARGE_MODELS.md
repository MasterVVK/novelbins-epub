# Работа с большими моделями Ollama

## Проблема
Большие модели Ollama (например, `gemma3:27b-it-qat` весом 22+ GB) могут не успевать загружаться при тестировании через веб-интерфейс из-за таймаутов.

## Решения

### 1. Предварительная загрузка модели (РЕКОМЕНДУЕТСЯ)

Перед добавлением модели в веб-интерфейс, загрузите её в Ollama вручную:

```bash
# Загрузите и инициализируйте модель
ollama run gemma3:27b-it-qat

# После появления промпта модель загружена
# Можно выйти с помощью /bye или Ctrl+D
```

После этого модель останется в памяти и будет быстро отвечать на запросы.

### 2. Проверка загруженных моделей

Проверить, какие модели сейчас загружены в память:

```bash
# Список всех моделей
ollama list

# Проверка конкретной модели
ollama ps
```

### 3. Настройка keep_alive

Можно настроить время, которое модель остается в памяти:

```bash
# Держать модель в памяти 30 минут после последнего использования
curl http://localhost:11434/api/generate -d '{
  "model": "gemma3:27b-it-qat",
  "keep_alive": "30m"
}'

# Держать модель в памяти всегда
curl http://localhost:11434/api/generate -d '{
  "model": "gemma3:27b-it-qat",
  "keep_alive": "-1"
}'
```

### 4. Оптимизация загрузки

Для ускорения загрузки больших моделей:

1. **Используйте SSD**: Модели загружаются с диска, SSD значительно ускоряет процесс
2. **Достаточно RAM**: Убедитесь, что есть достаточно оперативной памяти
3. **GPU память**: Для моделей 20+ GB нужна видеокарта с большим объемом VRAM

### 5. Альтернативные модели

Если модель слишком большая, рассмотрите альтернативы:

| Модель | Размер | Качество | Скорость |
|--------|--------|----------|----------|
| gemma3:27b-it-qat | 22 GB | Отличное | Медленно |
| qwen2.5:32b | 20 GB | Отличное | Медленно |
| qwen2.5:14b | 8.9 GB | Хорошее | Средне |
| qwen2.5:7b | 4.7 GB | Хорошее | Быстро |
| llama3.2:3b | 2.0 GB | Среднее | Очень быстро |

### 6. Проблемы с таймаутом в веб-интерфейсе

Если модель не успевает загрузиться при тестировании через веб-интерфейс:

1. Предварительно загрузите модель через `ollama run`
2. Только после этого добавляйте её в веб-интерфейс
3. При тестировании модель уже будет в памяти и ответит быстро

### 7. Мониторинг использования ресурсов

Во время загрузки модели:

```bash
# Мониторинг GPU
nvidia-smi -l 1

# Мониторинг CPU и памяти
htop

# Логи Ollama
journalctl -u ollama -f
```

## Текущие настройки таймаутов

- **Тестирование Ollama**: 5 минут (300 секунд)
- **Использование Ollama в продакшене**: 5 минут (300 секунд)
- **Обычные запросы после загрузки**: 1 минута (60 секунд)

## Рекомендация

Для моделей больше 15 GB всегда используйте предварительную загрузку через `ollama run` перед добавлением в веб-интерфейс.