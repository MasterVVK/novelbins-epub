"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –≥–ª–æ—Å—Å–∞—Ä–∏—è
"""
import os
import time
import json
import re
import logging
from typing import Dict, List, Optional, Tuple
import httpx
from httpx_socks import SyncProxyTransport
from app.models import Chapter, Translation, GlossaryItem, PromptTemplate
from app import db
from app.services.settings_service import SettingsService

logger = logging.getLogger(__name__)


class TranslatorConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞"""
    def __init__(self, api_keys: List[str] = None, proxy_url: Optional[str] = None, 
                 model_name: str = None, temperature: float = None, max_output_tokens: int = None):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
        self.api_keys = api_keys or SettingsService.get_gemini_api_keys()
        self.proxy_url = proxy_url or SettingsService.get_proxy_url() or os.getenv('PROXY_URL')
        self.model_name = model_name or SettingsService.get_default_model()
        self.temperature = temperature or SettingsService.get_default_temperature()
        self.max_output_tokens = max_output_tokens or SettingsService.get_max_tokens()


class LLMTranslator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ LLM API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏ –∏ —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–µ–π"""

    def __init__(self, config: TranslatorConfig):
        self.config = config
        self.current_key_index = 0
        self.failed_keys = set()

        # HTTP –∫–ª–∏–µ–Ω—Ç —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
        timeout_config = httpx.Timeout(
            connect=30.0,      # –í—Ä–µ–º—è –Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            read=300.0,        # –í—Ä–µ–º—è –Ω–∞ —á—Ç–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ (5 –º–∏–Ω—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤)
            write=30.0,        # –í—Ä–µ–º—è –Ω–∞ –æ—Ç–ø—Ä–∞–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞
            pool=30.0          # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –ø—É–ª–∞
        )

        if config.proxy_url:
            self.transport = SyncProxyTransport.from_url(config.proxy_url)
            self.client = httpx.Client(transport=self.transport, timeout=timeout_config)
        else:
            self.client = httpx.Client(timeout=timeout_config)

        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{config.model_name}:generateContent"

    @property
    def current_key(self) -> str:
        return self.config.api_keys[self.current_key_index]

    def switch_to_next_key(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–ª—é—á"""
        self.current_key_index = (self.current_key_index + 1) % len(self.config.api_keys)
        print(f"  ‚Üª –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∫–ª—é—á #{self.current_key_index + 1}")

    def mark_key_as_failed(self):
        """–ü–æ–º–µ—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–ª—é—á –∫–∞–∫ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–π"""
        self.failed_keys.add(self.current_key_index)
        print(f"  ‚ùå –ö–ª—é—á #{self.current_key_index + 1} –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–π")

    def reset_failed_keys(self):
        """–°–±—Ä–æ—Å —Å–ø–∏—Å–∫–∞ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –∫–ª—é—á–µ–π"""
        self.failed_keys.clear()
        print("  üîÑ –°–±—Ä–æ—Å —Å–ø–∏—Å–∫–∞ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –∫–ª—é—á–µ–π")

    def all_keys_failed(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –∫–ª—é—á–∏ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–µ"""
        return len(self.failed_keys) == len(self.config.api_keys)

    def make_request(self, system_prompt: str, user_prompt: str, temperature: float = None) -> Optional[str]:
        """–ë–∞–∑–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API —Å —É–º–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ API Gemini (–º–æ–¥–µ–ª—å: {self.config.model_name})")
        
        generation_config = {
            "temperature": temperature or self.config.temperature,
            "topP": 0.95,
            "topK": 40,
            "maxOutputTokens": self.config.max_output_tokens
        }

        max_attempts = len(self.config.api_keys) * 2
        logger.info(f"üîÑ –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫: {max_attempts}, –¥–æ—Å—Ç—É–ø–Ω–æ –∫–ª—é—á–µ–π: {len(self.config.api_keys)}")

        for attempt in range(max_attempts):
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –∫–ª—é—á –≤ —Å–ø–∏—Å–∫–µ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è
            if self.current_key_index in self.failed_keys:
                logger.info(f"üîÑ –ö–ª—é—á #{self.current_key_index + 1} –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–π, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è")
                self.switch_to_next_key()
                continue

            try:
                logger.info(f"üì§ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á #{self.current_key_index + 1} –∏–∑ {len(self.config.api_keys)}")
                print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á #{self.current_key_index + 1} –∏–∑ {len(self.config.api_keys)}")

                logger.info(f"üåê –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ {self.api_url}")
                response = self.client.post(
                    self.api_url,
                    params={"key": self.current_key},
                    headers={"Content-Type": "application/json"},
                    json={
                        "generationConfig": generation_config,
                        "contents": [{
                            "parts": [
                                {"text": system_prompt},
                                {"text": user_prompt}
                            ]
                        }]
                    }
                )

                logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç API, —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç API, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {list(data.keys())}")
                    
                    if 'candidates' in data and data['candidates']:
                        content = data['candidates'][0]['content']
                        if 'parts' in content and content['parts']:
                            result_text = content['parts'][0]['text']
                            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞, –¥–ª–∏–Ω–∞: {len(result_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                            return result_text
                    
                    logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {data}")
                    print(f"   ‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {data}")
                    self.mark_key_as_failed()
                    
                elif response.status_code == 429:  # Rate limit
                    logger.warning(f"‚è≥ Rate limit –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}")
                    print(f"   ‚è≥ Rate limit –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}")
                    self.mark_key_as_failed()
                    
                elif response.status_code == 400:  # Bad request
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}: {response.text}")
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}: {response.text}")
                    self.mark_key_as_failed()
                    
                else:
                    logger.error(f"‚ùå HTTP {response.status_code} –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}")
                    print(f"   ‚ùå HTTP {response.status_code} –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}")
                    self.mark_key_as_failed()

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}: {e}", exc_info=True)
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –¥–ª—è –∫–ª—é—á–∞ #{self.current_key_index + 1}: {e}")
                self.mark_key_as_failed()

            # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
            logger.info(f"‚è≥ –ü–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π")
            time.sleep(2)

        logger.error("‚ùå –í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        print("   ‚ùå –í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
        return None

    def translate_text(self, text: str, system_prompt: str, context: str = "") -> Optional[str]:
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
        user_prompt = f"{context}\n\n–¢–ï–ö–°–¢ –î–õ–Ø –ü–ï–†–ï–í–û–î–ê:\n{text}"
        return self.make_request(system_prompt, user_prompt)

    def generate_summary(self, text: str, summary_prompt: str) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ –≥–ª–∞–≤—ã"""
        user_prompt = f"–¢–ï–ö–°–¢ –ì–õ–ê–í–´:\n{text}"
        return self.make_request(summary_prompt, user_prompt, temperature=0.3)

    def extract_terms(self, text: str, extraction_prompt: str, existing_glossary: Dict) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        glossary_text = self.format_glossary_for_prompt(existing_glossary)
        user_prompt = f"–°–£–©–ï–°–¢–í–£–Æ–©–ò–ô –ì–õ–û–°–°–ê–†–ò–ô:\n{glossary_text}\n\n–¢–ï–ö–°–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n{text}"
        return self.make_request(extraction_prompt, user_prompt, temperature=0.2)

    def format_glossary_for_prompt(self, glossary: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        lines = []
        
        if glossary.get('characters'):
            lines.append("–ü–ï–†–°–û–ù–ê–ñ–ò:")
            for eng, rus in sorted(glossary['characters'].items()):
                lines.append(f"- {eng} = {rus}")
            lines.append("")
        
        if glossary.get('locations'):
            lines.append("–õ–û–ö–ê–¶–ò–ò:")
            for eng, rus in sorted(glossary['locations'].items()):
                lines.append(f"- {eng} = {rus}")
            lines.append("")
        
        if glossary.get('terms'):
            lines.append("–¢–ï–†–ú–ò–ù–´:")
            for eng, rus in sorted(glossary['terms'].items()):
                lines.append(f"- {eng} = {rus}")
            lines.append("")
        
        if glossary.get('techniques'):
            lines.append("–¢–ï–•–ù–ò–ö–ò:")
            for eng, rus in sorted(glossary['techniques'].items()):
                lines.append(f"- {eng} = {rus}")
            lines.append("")
        
        if glossary.get('artifacts'):
            lines.append("–ê–†–¢–ï–§–ê–ö–¢–´:")
            for eng, rus in sorted(glossary['artifacts'].items()):
                lines.append(f"- {eng} = {rus}")
            lines.append("")
        
        return "\n".join(lines) if lines else "–ì–ª–æ—Å—Å–∞—Ä–∏–π –ø—É—Å—Ç"


class TranslationContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≥–ª–∞–≤—ã"""
    
    def __init__(self, novel_id: int):
        self.novel_id = novel_id
        self.previous_summaries = []
        self.glossary = {}
        self._load_context()
    
    def _load_context(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—é–º–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≥–ª–∞–≤ (–¥–æ 5)
        from app.models import Chapter
        chapters = Chapter.query.filter_by(
            novel_id=self.novel_id, 
            status='translated'
        ).order_by(Chapter.chapter_number.desc()).limit(5).all()
        
        for chapter in reversed(chapters):
            if chapter.current_translation and chapter.current_translation.summary:
                self.previous_summaries.append({
                    'chapter': chapter.chapter_number,
                    'summary': chapter.current_translation.summary
                })
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
        self.glossary = GlossaryItem.get_glossary_dict(self.novel_id)
    
    def build_context_prompt(self) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        lines = []

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—é–º–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≥–ª–∞–≤
        if self.previous_summaries:
            lines.append("–ö–û–ù–¢–ï–ö–°–¢ –ü–†–ï–î–´–î–£–©–ò–• –ì–õ–ê–í:")
            lines.append("=" * 50)
            for item in self.previous_summaries:
                lines.append(f"\n–ì–ª–∞–≤–∞ {item['chapter']}:")
                lines.append(item['summary'])
            lines.append("\n" + "=" * 50 + "\n")

        # –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
        if self.glossary['characters']:
            lines.append("–£–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ï –ü–ï–†–ï–í–û–î–´ –ò–ú–Å–ù:")
            for eng, rus in sorted(self.glossary['characters'].items()):
                lines.append(f"- {eng} ‚Üí {rus}")
            lines.append("")

        if self.glossary['locations']:
            lines.append("–£–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ï –ü–ï–†–ï–í–û–î–´ –õ–û–ö–ê–¶–ò–ô:")
            for eng, rus in sorted(self.glossary['locations'].items()):
                lines.append(f"- {eng} ‚Üí {rus}")
            lines.append("")

        if self.glossary['terms']:
            lines.append("–£–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ï –ü–ï–†–ï–í–û–î–´ –¢–ï–†–ú–ò–ù–û–í:")
            for eng, rus in sorted(self.glossary['terms'].items()):
                lines.append(f"- {eng} ‚Üí {rus}")
            lines.append("")

        return "\n".join(lines)


class TranslatorService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–≤–æ–¥–∞"""

    def __init__(self, config: Dict = None):
        logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TranslatorService")
        
        self.config = TranslatorConfig(**config) if config else TranslatorConfig()
        logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞: –º–æ–¥–µ–ª—å={self.config.model_name}, –ø—Ä–æ–∫—Å–∏={self.config.proxy_url}, –∫–ª—é—á–µ–π={len(self.config.api_keys)}")
        
        logger.info("üîß –°–æ–∑–¥–∞–µ–º LLMTranslator")
        self.translator = LLMTranslator(self.config)
        logger.info("‚úÖ TranslatorService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")

    def translate_chapter(self, chapter: Chapter) -> bool:
        """–ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏ –≥–ª–æ—Å—Å–∞—Ä–∏—è"""
        logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {chapter.chapter_number}: {chapter.original_title}")
        print(f"üîÑ –ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {chapter.chapter_number}: {chapter.original_title}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –Ω–æ–≤–µ–ª–ª—ã
            logger.info(f"üìã –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}")
            prompt_template = chapter.novel.get_prompt_template()
            if not prompt_template:
                logger.error(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}")
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞")
                return False
            
            logger.info(f"‚úÖ –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –ø–æ–ª—É—á–µ–Ω: {prompt_template.name}")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞
            logger.info(f"üîß –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}")
            context = TranslationContext(chapter.novel_id)
            context_prompt = context.build_context_prompt()
            logger.info(f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ —Å–æ–∑–¥–∞–Ω, –¥–ª–∏–Ω–∞: {len(context_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            logger.info(f"üìù –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≥–ª–∞–≤—ã {chapter.chapter_number}")
            text_to_translate = self.preprocess_text(chapter.original_text)
            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω, –¥–ª–∏–Ω–∞: {len(text_to_translate)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏
            logger.info(f"‚úÇÔ∏è –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã {chapter.chapter_number} –Ω–∞ —á–∞—Å—Ç–∏")
            text_parts = self.split_long_text(text_to_translate)
            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(text_parts)} —á–∞—Å—Ç–µ–π")
            
            translated_parts = []
            
            for i, part in enumerate(text_parts):
                logger.info(f"üîÑ –ü–µ—Ä–µ–≤–æ–¥ —á–∞—Å—Ç–∏ {i+1}/{len(text_parts)} –≥–ª–∞–≤—ã {chapter.chapter_number}")
                print(f"   üìù –ü–µ—Ä–µ–≤–æ–¥ —á–∞—Å—Ç–∏ {i+1}/{len(text_parts)}")
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —á–∞—Å—Ç—å
                logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–µ—Ä–µ–≤–æ–¥ —á–∞—Å—Ç–∏ {i+1}")
                translated_part = self.translator.translate_text(
                    part, 
                    prompt_template.translation_prompt,
                    context_prompt
                )
                
                if not translated_part:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —á–∞—Å—Ç–∏ {i+1} –≥–ª–∞–≤—ã {chapter.chapter_number}")
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —á–∞—Å—Ç–∏ {i+1}")
                    return False
                
                logger.info(f"‚úÖ –ß–∞—Å—Ç—å {i+1} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ, –¥–ª–∏–Ω–∞: {len(translated_part)} —Å–∏–º–≤–æ–ª–æ–≤")
                translated_parts.append(translated_part)
                time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏
            logger.info(f"üîó –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏ –≥–ª–∞–≤—ã {chapter.chapter_number}")
            full_translation = "\n\n".join(translated_parts)
            logger.info(f"‚úÖ –ß–∞—Å—Ç–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã, –æ–±—â–∞—è –¥–ª–∏–Ω–∞: {len(full_translation)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
            logger.info(f"üìÑ –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã {chapter.chapter_number}")
            title, content = self.extract_title_and_content(full_translation)
            logger.info(f"‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫: '{title}', –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥
            logger.info(f"üîç –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {chapter.chapter_number}")
            validation = self.validate_translation(chapter.original_text, content, chapter.chapter_number)
            if validation['critical']:
                logger.error(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –ø–µ—Ä–µ–≤–æ–¥–µ –≥–ª–∞–≤—ã {chapter.chapter_number}: {validation['critical_issues']}")
                print(f"   ‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –ø–µ—Ä–µ–≤–æ–¥–µ: {validation['critical_issues']}")
                return False
            
            logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞, –∫–∞—á–µ—Å—Ç–≤–æ: {self.calculate_quality_score(validation)}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ
            summary = None
            if prompt_template.summary_prompt:
                logger.info(f"üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}")
                summary = self.translator.generate_summary(content, prompt_template.summary_prompt)
                if summary:
                    logger.info(f"‚úÖ –†–µ–∑—é–º–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ, –¥–ª–∏–Ω–∞: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—é–º–µ –¥–ª—è –≥–ª–∞–≤—ã {chapter.chapter_number}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            if prompt_template.terms_extraction_prompt:
                logger.info(f"üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –≥–ª–∞–≤—ã {chapter.chapter_number}")
                new_terms = self.extract_new_terms(content, prompt_template.terms_extraction_prompt, context.glossary)
                if new_terms:
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(new_terms)} –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")
                    self.save_new_terms(new_terms, chapter.novel_id, chapter.chapter_number)
                else:
                    logger.info(f"‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –≥–ª–∞–≤–µ {chapter.chapter_number}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {chapter.chapter_number} –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            translation = Translation(
                chapter_id=chapter.id,
                translated_title=title,
                translated_text=content,
                summary=summary,
                quality_score=self.calculate_quality_score(validation),
                translation_time=time.time(),
                metadata={
                    'template_used': prompt_template.name,
                    'validation': validation,
                    'parts_count': len(text_parts)
                }
            )
            
            db.session.add(translation)
            chapter.status = 'translated'
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –≥–ª–∞–≤ –≤ –Ω–æ–≤–µ–ª–ª–µ
            from app.models import Novel
            novel = Novel.query.get(chapter.novel_id)
            if novel:
                translated_count = Chapter.query.filter_by(novel_id=chapter.novel_id, status='translated', is_active=True).count()
                novel.translated_chapters = translated_count
                logger.info(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω —Å—á–µ—Ç—á–∏–∫ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –≥–ª–∞–≤: {translated_count}")
            
            db.session.commit()
            
            logger.info(f"‚úÖ –ì–ª–∞–≤–∞ {chapter.chapter_number} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            print(f"   ‚úÖ –ì–ª–∞–≤–∞ {chapter.chapter_number} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –≥–ª–∞–≤—ã {chapter.chapter_number}: {e}", exc_info=True)
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –≥–ª–∞–≤—ã {chapter.chapter_number}: {e}")
            db.session.rollback()
            return False

    def preprocess_text(self, text: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–±–∑–∞—Ü–µ–≤)"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–∞–±–∑–∞—Ü—ã)
        text = text.replace('\n\n', '¬ßPARAGRAPH_BREAK¬ß')
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'[ \t]+', ' ', text)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã (–±–æ–ª–µ–µ 3 –ø–æ–¥—Ä—è–¥)
        text = re.sub(r'(.)\1{3,}', r'\1\1\1', text)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = text.replace('¬ßPARAGRAPH_BREAK¬ß', '\n\n')
        
        return text.strip()

    def split_long_text(self, text: str, max_words: int = 1200) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∞–±–∑–∞—Ü–µ–≤"""
        paragraphs = text.split('\n\n')
        parts = []
        current_part = []
        current_words = 0
        
        for paragraph in paragraphs:
            paragraph_words = len(paragraph.split())
            
            if current_words + paragraph_words > max_words and current_part:
                parts.append('\n\n'.join(current_part))
                current_part = [paragraph]
                current_words = paragraph_words
            else:
                current_part.append(paragraph)
                current_words += paragraph_words
        
        if current_part:
            parts.append('\n\n'.join(current_part))
        
        return parts

    def extract_title_and_content(self, translated_text: str) -> Tuple[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        lines = translated_text.strip().split('\n')
        
        if lines:
            title = lines[0].strip()
            content = '\n'.join(lines[1:]).strip()
            return title, content
        
        return "", translated_text

    def validate_translation(self, original: str, translated: str, chapter_num: int) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º —Å–∫—Ä–∏–ø—Ç–µ)"""
        issues = []
        warnings = []
        critical_issues = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –¥–ª–∏–Ω—ã
        orig_len = len(original)
        trans_len = len(translated)
        ratio = trans_len / orig_len if orig_len > 0 else 0

        # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –ø–µ—Ä–µ–≤–æ–¥ –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω–µ–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ 10-30%
        if ratio < 0.6:
            critical_issues.append(f"–ü–µ—Ä–µ–≤–æ–¥ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {ratio:.2f} –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")
        elif ratio < 0.9:
            issues.append(f"–ü–µ—Ä–µ–≤–æ–¥ –∫–æ—Ä–æ—Ç–∫–∏–π: {ratio:.2f} –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")
        elif ratio > 1.6:
            warnings.append(f"–ü–µ—Ä–µ–≤–æ–¥ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {ratio:.2f} –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–±–∑–∞—Ü–µ–≤ (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º —Å–∫—Ä–∏–ø—Ç–µ)
        orig_paragraphs = len([p for p in original.split('\n\n') if p.strip()])
        trans_paragraphs = len([p for p in translated.split('\n\n') if p.strip()])

        para_diff = abs(orig_paragraphs - trans_paragraphs)
        para_ratio = trans_paragraphs / orig_paragraphs if orig_paragraphs > 0 else 0

        # –ú–µ–Ω–µ–µ 60% –∞–±–∑–∞—Ü–µ–≤ - –∫—Ä–∏—Ç–∏—á–Ω–æ (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º —Å–∫—Ä–∏–ø—Ç–µ)
        if para_ratio < 0.6:
            critical_issues.append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∞–±–∑–∞—Ü–∞—Ö: {orig_paragraphs} ‚Üí {trans_paragraphs} ({para_ratio:.1%})")
        elif para_diff > 2:
            issues.append(f"–†–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∞–±–∑–∞—Ü–µ–≤: {orig_paragraphs} ‚Üí {trans_paragraphs}")
        elif para_diff > 0:
            warnings.append(f"–ù–µ–±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∞–±–∑–∞—Ü–∞—Ö: {orig_paragraphs} ‚Üí {trans_paragraphs}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —á–∏—Å–µ–ª (–≤–∞–∂–Ω–æ –¥–ª—è —Å—è–Ω—å—Å—è)
        import re
        orig_numbers = re.findall(r'\b\d+\b', original)
        trans_numbers = re.findall(r'\b\d+\b', translated)

        if len(orig_numbers) != len(trans_numbers):
            issues.append(f"–†–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —á–∏—Å–µ–ª: {len(orig_numbers)} ‚Üí {len(trans_numbers)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        stats = {
            'length_ratio': ratio,
            'paragraph_diff': para_diff,
            'paragraph_ratio': para_ratio,
            'original_words': len(original.split()),
            'translated_words': len(translated.split()),
            'numbers_preserved': len(orig_numbers) == len(trans_numbers)
        }

        return {
            'valid': len(issues) == 0 and len(critical_issues) == 0,
            'critical': len(critical_issues) > 0,
            'issues': issues,
            'warnings': warnings,
            'critical_issues': critical_issues,
            'stats': stats
        }

    def calculate_quality_score(self, validation: Dict) -> int:
        """–†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        score = 10
        
        # –®—Ç—Ä–∞—Ñ—ã –∑–∞ –ø—Ä–æ–±–ª–µ–º—ã
        score -= len(validation['critical_issues']) * 3
        score -= len(validation['issues']) * 1
        score -= len(validation['warnings']) * 0.5
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ —Ö–æ—Ä–æ—à–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        if validation['stats']['length_ratio'] >= 0.9 and validation['stats']['length_ratio'] <= 1.3:
            score += 1
        
        return max(1, min(10, int(score)))

    def extract_new_terms(self, text: str, extraction_prompt: str, existing_glossary: Dict) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç: {extraction_prompt[:200]}...")
        
        result = self.translator.extract_terms(text, extraction_prompt, existing_glossary)
        if not result:
            logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ—Ä–º–∏–Ω—ã - –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            return None
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª–∏–Ω–æ–π {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
        return self.parse_extraction_result(result)

    def parse_extraction_result(self, text: str) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        result = {'characters': {}, 'locations': {}, 'terms': {}, 'techniques': {}, 'artifacts': {}}
        
        logger.info(f"üîç –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤, –¥–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"üìÑ –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞: {text[:500]}...")
        
        current_section = None
        for line in text.split('\n'):
            line = line.strip()
            
            if '–ü–ï–†–°–û–ù–ê–ñ–ò:' in line:
                current_section = 'characters'
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è: {current_section}")
            elif '–õ–û–ö–ê–¶–ò–ò:' in line:
                current_section = 'locations'
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è: {current_section}")
            elif '–¢–ï–†–ú–ò–ù–´:' in line:
                current_section = 'terms'
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è: {current_section}")
            elif '–¢–ï–•–ù–ò–ö–ò:' in line:
                current_section = 'techniques'
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è: {current_section}")
            elif '–ê–†–¢–ï–§–ê–ö–¢–´:' in line:
                current_section = 'artifacts'
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è: {current_section}")
            elif line.startswith('- ') and current_section:
                if '–Ω–µ—Ç –Ω–æ–≤—ã—Ö' in line.lower():
                    logger.info(f"‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É '–Ω–µ—Ç –Ω–æ–≤—ã—Ö': {line}")
                    continue
                
                parts = line[2:].split(' = ')
                if len(parts) == 2:
                    eng, rus = parts[0].strip(), parts[1].strip()
                    if eng and rus and eng != rus:
                        logger.info(f"üîç –ù–∞–π–¥–µ–Ω —Ç–µ—Ä–º–∏–Ω: {eng} = {rus}")
                        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤
                        if self.is_valid_term(eng, rus):
                            result[current_section][eng] = rus
                            logger.info(f"‚úÖ –¢–µ—Ä–º–∏–Ω –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {eng} = {rus}")
                        else:
                            logger.info(f"‚ùå –¢–µ—Ä–º–∏–Ω –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {eng} = {rus}")
                    else:
                        logger.info(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ—Ä–º–∏–Ω–∞: {line}")
                else:
                    logger.info(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏: {line}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for category, terms in result.items():
            logger.info(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏—è {category}: {len(terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
            for eng, rus in terms.items():
                logger.info(f"  - {eng} = {rus}")
        
        return result
    
    def is_valid_term(self, eng: str, rus: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ç–µ—Ä–º–∏–Ω–∞"""
        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã (–±–æ–ª—å—à–µ 50 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(eng) > 50 or len(rus) > 50:
            return False
        
        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–º–µ–Ω—å—à–µ 2 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(eng) < 2 or len(rus) < 2:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—ã—á–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ)
        common_words = ['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by']
        if eng.lower() in common_words:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Å–æ–¥–µ—Ä–∂–∞—Ç –º–Ω–æ–≥–æ –ø—Ä–æ–±–µ–ª–æ–≤)
        if eng.count(' ') > 5 or rus.count(' ') > 5:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —á–∏—Å–ª–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if any(char.isdigit() for char in eng) or any(char.isdigit() for char in rus):
            return False
        
        return True

    def save_new_terms(self, new_terms: Dict, novel_id: int, chapter_number: int):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –≥–ª–æ—Å—Å–∞—Ä–∏–π"""
        total_saved = 0
        for category, terms in new_terms.items():
            logger.info(f"üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é {category}: {len(terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤")
            for eng, rus in terms.items():
                logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ä–º–∏–Ω: {eng} = {rus}")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
                existing = GlossaryItem.query.filter_by(
                    novel_id=novel_id,
                    english_term=eng,
                    is_active=True
                ).first()
                
                if not existing:
                    glossary_item = GlossaryItem(
                        novel_id=novel_id,
                        english_term=eng,
                        russian_term=rus,
                        category=category,
                        first_appearance_chapter=chapter_number,
                        is_auto_generated=True
                    )
                    db.session.add(glossary_item)
                    total_saved += 1
                    logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–æ–≤—ã–π —Ç–µ—Ä–º–∏–Ω: {eng} = {rus} (–∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category})")
                else:
                    logger.info(f"‚ÑπÔ∏è –¢–µ—Ä–º–∏–Ω —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {eng}")
        
        db.session.commit()
        logger.info(f"üìö –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {total_saved}")
        print(f"   üìö –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {total_saved} –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤") 