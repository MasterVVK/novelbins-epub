"""
–°–µ—Ä–≤–∏—Å –¥–ª—è LLM-–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –∏ —Ä—É—Å—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
"""
import json
import logging
import asyncio
from typing import Dict, List, Optional, Tuple
from datetime import datetime

from app import db
from app.models import Chapter, BilingualAlignment, BilingualPromptTemplate
from app.services.ai_adapter_service import AIAdapterService
from app.services.bilingual_prompt_template_service import BilingualPromptTemplateService
from app.services.log_service import LogService

logger = logging.getLogger(__name__)


class BilingualAlignmentService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–≤—É—è–∑—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM.
    –ê–Ω–∞–ª–æ–≥ OriginalAwareEditorService, –Ω–æ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è, –∞ –Ω–µ —Ä–µ–¥–∞–∫—Ç—É—Ä—ã.
    """

    def __init__(self, model_id: Optional[int] = None, template_id: Optional[int] = None):
        """
        Args:
            model_id: ID AI –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (–µ—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è)
            template_id: ID —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ (–µ—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∏–ª–∏ –∏–∑ –Ω–æ–≤–µ–ª–ª—ã)
        """
        self.model_id = model_id
        self.template_id = template_id

    def align_chapter(
        self,
        chapter: Chapter,
        force_refresh: bool = False,
        save_to_cache: bool = True
    ) -> List[Dict]:
        """
        –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≥–ª–∞–≤—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM

        Args:
            chapter: –ì–ª–∞–≤–∞ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
            force_refresh: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à)
            save_to_cache: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ë–î

        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –≤—ã—Ä–∞–≤–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ä
            [
                {
                    "ru": "–†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç",
                    "zh": "‰∏≠ÊñáÊñáÊú¨",
                    "type": "dialogue",
                    "confidence": 0.95
                },
                ...
            ]
        """
        log_prefix = f"[Novel:{chapter.novel_id}, Ch:{chapter.chapter_number}]"

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if not force_refresh:
            cached = BilingualAlignment.query.filter_by(chapter_id=chapter.id).first()
            if cached:
                LogService.log_info(
                    f"{log_prefix} –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (quality={cached.quality_score:.2f}, –º–µ—Ç–æ–¥={cached.alignment_method})",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )
                return cached.alignment_data.get('alignments', [])

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        russian_text = self._get_russian_text(chapter)
        chinese_text = chapter.original_text

        if not russian_text:
            LogService.log_error(
                f"{log_prefix} –ù–µ—Ç —Ä—É—Å—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è",
                novel_id=chapter.novel_id,
                chapter_id=chapter.id
            )
            return []

        if not chinese_text:
            LogService.log_warning(
                f"{log_prefix} –ù–µ—Ç –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ - —Å–æ–∑–¥–∞–µ–º –º–æ–Ω–æ—è–∑—ã—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç",
                novel_id=chapter.novel_id,
                chapter_id=chapter.id
            )
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç (fallback)
            mono_alignment = self._create_monolingual_alignment(russian_text)
            if save_to_cache:
                self._save_to_cache(
                    chapter=chapter,
                    alignment_data={'alignments': mono_alignment, 'stats': {'total_pairs': len(mono_alignment)}},
                    quality_score=1.0,
                    model_name='monolingual',
                    template_id=None
                )
            return mono_alignment

        # 3. –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞
        template = self._get_template(chapter.novel)
        if not template:
            LogService.log_error(
                f"{log_prefix} –ù–µ –Ω–∞–π–¥–µ–Ω —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è",
                novel_id=chapter.novel_id,
                chapter_id=chapter.id
            )
            return self._fallback_regex_alignment(russian_text, chinese_text, chapter)

        # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω–∞—è ‚Üí –∏–∑ —à–∞–±–ª–æ–Ω–∞ ‚Üí –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è (None)
        model_id_to_use = self.model_id or (template.default_model_id if template else None)

        # 5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        LogService.log_info(
            f"{log_prefix} –ù–∞—á–∏–Ω–∞–µ–º LLM –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ (RU: {len(russian_text)} —Å–∏–º–≤–æ–ª–æ–≤, ZH: {len(chinese_text)} —Å–∏–º–≤–æ–ª–æ–≤, —à–∞–±–ª–æ–Ω: {template.name})",
            novel_id=chapter.novel_id,
            chapter_id=chapter.id
        )

        prompt = self._build_alignment_prompt(template, russian_text, chinese_text)

        # 6. –ó–∞–ø—Ä–æ—Å –∫ LLM —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –ø–æ—Ç–µ—Ä–µ —Ç–µ–∫—Å—Ç–∞
        max_attempts = 3
        # –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –ø–æ–∫—Ä—ã—Ç–∏—è:
        # –ü–æ–ø—ã—Ç–∫–∞ 1: 98% (—Å—Ç—Ä–æ–≥–æ)
        # –ü–æ–ø—ã—Ç–∫–∞ 2: 96% (–º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–æ)
        # –ü–æ–ø—ã—Ç–∫–∞ 3: 95% (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ –ø—Ä–∏–µ–º–ª–µ–º–æ)
        coverage_thresholds = {
            1: 0.98,
            2: 0.96,
            3: 0.95
        }

        ai_adapter = AIAdapterService(
            model_id=model_id_to_use,
            chapter_id=chapter.id
        )

        alignment_result = None
        quality_score = 0.0
        coverage_ru = 0.0
        coverage_zh = 0.0
        avg_confidence = 0.0

        for attempt in range(1, max_attempts + 1):
            # –ü–æ—Ä–æ–≥ –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
            min_volume_coverage = coverage_thresholds[attempt]
            try:
                LogService.log_info(
                    f"{log_prefix} –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts} LLM –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (–ø–æ—Ä–æ–≥ –ø–æ–∫—Ä—ã—Ç–∏—è: {min_volume_coverage * 100:.0f}%)",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )

                start_time = datetime.now()

                # –í—ã–∑—ã–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ asyncio.run()
                result = asyncio.run(ai_adapter.generate_content(
                    system_prompt=template.system_prompt if template.system_prompt else "",
                    user_prompt=prompt,
                    temperature=template.temperature,
                    max_tokens=template.max_tokens
                ))

                duration = (datetime.now() - start_time).total_seconds()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
                if not result.get('success'):
                    raise Exception(result.get('error', 'Unknown error from AI adapter'))

                response = result['content']

                LogService.log_info(
                    f"{log_prefix} LLM –∑–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.1f}—Å (–º–æ–¥–µ–ª—å: {ai_adapter.model.name})",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )

                # –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞
                try:
                    alignment_result = self._parse_llm_response(response)
                except Exception as e:
                    LogService.log_error(
                        f"{log_prefix} –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}",
                        novel_id=chapter.novel_id,
                        chapter_id=chapter.id
                    )
                    if attempt == max_attempts:
                        return self._fallback_regex_alignment(russian_text, chinese_text, chapter)
                    continue

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
                is_valid, quality_score, coverage_ru, coverage_zh, avg_confidence = self._validate_alignment(
                    alignment_result.get('alignments', []),
                    russian_text,
                    chinese_text
                )

                if not is_valid:
                    LogService.log_warning(
                        f"{log_prefix} –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (score={quality_score:.2f}, –ø–æ–ø—ã—Ç–∫–∞ {attempt})",
                        novel_id=chapter.novel_id,
                        chapter_id=chapter.id
                    )
                    if attempt == max_attempts:
                        return self._fallback_regex_alignment(russian_text, chinese_text, chapter)
                    continue

                # –ü–†–û–í–ï–†–ö–ê –û–ë–™–ï–ú–ê –¢–ï–ö–°–¢–ê
                volume_valid, volume_stats = self._check_volume_integrity(
                    alignment_result.get('alignments', []),
                    russian_text,
                    chinese_text,
                    min_coverage=min_volume_coverage
                )

                LogService.log_info(
                    f"{log_prefix} –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}, –ø–æ—Ä–æ–≥ {min_volume_coverage * 100:.0f}%): RU {volume_stats['coverage_ru_percent']}, ZH {volume_stats['coverage_zh_percent']}",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )

                if not volume_valid:
                    LogService.log_warning(
                        f"{log_prefix} ‚ö†Ô∏è –ü–æ—Ç–µ—Ä—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏! RU: {volume_stats['coverage_ru_percent']} (–Ω—É–∂–Ω–æ ‚â•{min_volume_coverage * 100:.0f}%), ZH: {volume_stats['coverage_zh_percent']} (–Ω—É–∂–Ω–æ ‚â•{min_volume_coverage * 100:.0f}%)",
                        novel_id=chapter.novel_id,
                        chapter_id=chapter.id
                    )

                    if attempt < max_attempts:
                        next_threshold = coverage_thresholds[attempt + 1]
                        LogService.log_info(
                            f"{log_prefix} üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (—Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Ä–æ–≥: {next_threshold * 100:.0f}%)...",
                            novel_id=chapter.novel_id,
                            chapter_id=chapter.id
                        )
                        continue
                    else:
                        LogService.log_error(
                            f"{log_prefix} ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è ({coverage_thresholds[3] * 100:.0f}%) –∑–∞ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback",
                            novel_id=chapter.novel_id,
                            chapter_id=chapter.id
                        )
                        return self._fallback_regex_alignment(russian_text, chinese_text, chapter)

                # –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã!
                LogService.log_info(
                    f"{log_prefix} ‚úÖ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {len(alignment_result['alignments'])} –ø–∞—Ä, –∫–∞—á–µ—Å—Ç–≤–æ {quality_score:.2f}, –ø–æ–∫—Ä—ã—Ç–∏–µ RU {volume_stats['coverage_ru_percent']}, ZH {volume_stats['coverage_zh_percent']}",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )
                break  # –£—Å–ø–µ—à–Ω–æ, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞

            except Exception as e:
                LogService.log_error(
                    f"{log_prefix} –û—à–∏–±–∫–∞ LLM –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}",
                    novel_id=chapter.novel_id,
                    chapter_id=chapter.id
                )
                if attempt == max_attempts:
                    return self._fallback_regex_alignment(russian_text, chinese_text, chapter)
                continue

        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if not alignment_result:
            return self._fallback_regex_alignment(russian_text, chinese_text, chapter)

        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
        if save_to_cache:
            self._save_to_cache(
                chapter=chapter,
                alignment_data=alignment_result,
                quality_score=quality_score,
                coverage_ru=coverage_ru,
                coverage_zh=coverage_zh,
                avg_confidence=avg_confidence,
                model_name=ai_adapter.model.name,
                template_id=template.id
            )

        return alignment_result.get('alignments', [])

    def _get_russian_text(self, chapter: Chapter) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä—É—Å—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥"""
        if chapter.edited_translation:
            return chapter.edited_translation.translated_text
        elif chapter.current_translation:
            return chapter.current_translation.translated_text
        return None

    def _get_template(self, novel) -> Optional[BilingualPromptTemplate]:
        """–ü–æ–ª—É—á–∏—Ç—å —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è"""
        # 1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π –≤ —Å–µ—Ä–≤–∏—Å–µ
        if self.template_id:
            template = BilingualPromptTemplateService.get_template_by_id(self.template_id)
            if template:
                return template

        # 2. –®–∞–±–ª–æ–Ω –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–π –∫ –Ω–æ–≤–µ–ª–ª–µ
        if novel and novel.bilingual_template:
            return novel.bilingual_template

        # 3. –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —à–∞–±–ª–æ–Ω
        return BilingualPromptTemplateService.get_default_template()

    def _build_alignment_prompt(
        self,
        template: BilingualPromptTemplate,
        russian_text: str,
        chinese_text: str
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫"""
        try:
            # –®–∞–≥ 1: –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏ –≤ —à–∞–±–ª–æ–Ω–µ
            # { ‚Üí {{ –∏ } ‚Üí }}
            escaped_template = template.alignment_prompt.replace('{', '{{').replace('}', '}}')

            # –®–∞–≥ 2: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞—à–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
            # {{chinese_text}} ‚Üí {chinese_text}
            # {{russian_text}} ‚Üí {russian_text}
            escaped_template = escaped_template.replace('{{chinese_text}}', '{chinese_text}')
            escaped_template = escaped_template.replace('{{russian_text}}', '{russian_text}')

            # –®–∞–≥ 3: –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º format()
            prompt = escaped_template.format(
                chinese_text=chinese_text,
                russian_text=russian_text
            )

            logger.info(f"–ü—Ä–æ–º–ø—Ç —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω (–¥–ª–∏–Ω–∞: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return prompt

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")
            logger.error(f"–®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {template.alignment_prompt[:500]}")
            raise

    def _parse_llm_response(self, response: str) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        import re

        original_response = response  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        response = response.strip()
        if response.startswith('```json'):
            response = response[7:]
        if response.startswith('```'):
            response = response[3:]
        if response.endswith('```'):
            response = response[:-3]
        response = response.strip()

        # –ü–æ–ø—ã—Ç–∫–∞ 1: –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
        try:
            result = json.loads(response)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if 'alignments' not in result:
                raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'alignments' –≤ JSON –æ—Ç–≤–µ—Ç–µ")

            return result

        except json.JSONDecodeError as e:
            logger.warning(f"–ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –Ω–µ —É–¥–∞–ª—Å—è: {e}")

            # –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—â–µ–º JSON –±–ª–æ–∫ —á–µ—Ä–µ–∑ regex
            # –ü–∞—Ç—Ç–µ—Ä–Ω: –∏—â–µ–º { ... "alignments": [ ... ] ... }
            json_pattern = r'\{[\s\S]*?"alignments"[\s\S]*?\][\s\S]*?\}'
            matches = re.findall(json_pattern, response)

            if matches:
                # –ë–µ—Ä–µ–º —Å–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø–æ–ª–Ω—ã–π JSON)
                json_candidate = max(matches, key=len)

                try:
                    result = json.loads(json_candidate)

                    if 'alignments' not in result:
                        raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'alignments' –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–º JSON")

                    logger.info(f"JSON —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω —á–µ—Ä–µ–∑ regex (–¥–ª–∏–Ω–∞: {len(json_candidate)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return result

                except json.JSONDecodeError as e2:
                    logger.error(f"Regex –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e2}")
                    logger.error(f"–ù–∞–π–¥–µ–Ω–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç JSON (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {json_candidate[:500]}")

            # –ü–æ–ø—ã—Ç–∫–∞ 3: –õ–æ–≥–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç –æ—Ç LLM")
            logger.error(f"–ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):\n{original_response[:1000]}")
            logger.error(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):\n{response[:1000]}")

            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {e}")

    def _validate_alignment(
        self,
        alignments: List[Dict],
        russian_text: str,
        chinese_text: str
    ) -> Tuple[bool, float, float, float, float]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è

        Returns:
            (is_valid, quality_score, coverage_ru, coverage_zh, avg_confidence)
        """
        if not alignments:
            return False, 0.0, 0.0, 0.0, 0.0

        # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
        aligned_ru = ' '.join([pair.get('ru', '') for pair in alignments])
        aligned_zh = ' '.join([pair.get('zh', '') for pair in alignments])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ –≤—ã—Ä–æ–≤–Ω—è–ª–∏)
        coverage_ru = len(aligned_ru) / len(russian_text) if russian_text else 0
        coverage_zh = len(aligned_zh) / len(chinese_text) if chinese_text else 0

        # –°—Ä–µ–¥–Ω—è—è confidence –∏–∑ LLM
        avg_confidence = sum([pair.get('confidence', 0.5) for pair in alignments]) / len(alignments)

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_score = (coverage_ru * 0.3 + coverage_zh * 0.3 + avg_confidence * 0.4)

        # –í–∞–ª–∏–¥–Ω–æ –µ—Å–ª–∏ –ø–æ–∫—Ä—ã—Ç–∏–µ > 80% –∏ confidence > 0.6
        is_valid = coverage_ru > 0.8 and coverage_zh > 0.8 and avg_confidence > 0.6

        return is_valid, quality_score, coverage_ru, coverage_zh, avg_confidence

    def _check_volume_integrity(
        self,
        alignments: List[Dict],
        russian_text: str,
        chinese_text: str,
        min_coverage: float = 0.95
    ) -> Tuple[bool, Dict]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–º–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç

        Args:
            alignments: –°–ø–∏—Å–æ–∫ –ø–∞—Ä —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            russian_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            chinese_text: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–∏—Ç–∞–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            min_coverage: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 95%)

        Returns:
            (is_valid, stats): –§–ª–∞–≥ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        if not alignments:
            return False, {'error': 'Empty alignments'}

        # –°–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä—ã
        aligned_ru_text = ''.join(pair.get('ru', '') for pair in alignments)
        aligned_zh_text = ''.join(pair.get('zh', '') for pair in alignments)

        # –£–ë–ò–†–ê–ï–ú –ü–ï–†–ï–ù–û–°–´ –°–¢–†–û–ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        # –ò—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        original_ru_clean = russian_text.replace('\n', '')
        original_zh_clean = chinese_text.replace('\n', '')

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        aligned_ru_clean = aligned_ru_text.replace('\n', '')
        aligned_zh_clean = aligned_zh_text.replace('\n', '')

        # –î–ª–∏–Ω—ã —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
        original_ru_length = len(russian_text)
        original_zh_length = len(chinese_text)
        aligned_ru_length = len(aligned_ru_text)
        aligned_zh_length = len(aligned_zh_text)

        # –î–ª–∏–Ω—ã –±–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ (–¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
        original_ru_clean_length = len(original_ru_clean)
        original_zh_clean_length = len(original_zh_clean)
        aligned_ru_clean_length = len(aligned_ru_clean)
        aligned_zh_clean_length = len(aligned_zh_clean)

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –ë–ï–ó –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫
        coverage_ru = aligned_ru_clean_length / original_ru_clean_length if original_ru_clean_length > 0 else 0
        coverage_zh = aligned_zh_clean_length / original_zh_clean_length if original_zh_clean_length > 0 else 0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å >= min_coverage
        is_valid = coverage_ru >= min_coverage and coverage_zh >= min_coverage

        stats = {
            # –° –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
            'original_ru_length': original_ru_length,
            'original_zh_length': original_zh_length,
            'aligned_ru_length': aligned_ru_length,
            'aligned_zh_length': aligned_zh_length,
            # –ë–ï–ó –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ (—Ä–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            'original_ru_clean_length': original_ru_clean_length,
            'original_zh_clean_length': original_zh_clean_length,
            'aligned_ru_clean_length': aligned_ru_clean_length,
            'aligned_zh_clean_length': aligned_zh_clean_length,
            # –ü–æ–∫—Ä—ã—Ç–∏–µ
            'coverage_ru': coverage_ru,
            'coverage_zh': coverage_zh,
            'coverage_ru_percent': f'{coverage_ru * 100:.2f}%',
            'coverage_zh_percent': f'{coverage_zh * 100:.2f}%',
            'is_valid': is_valid
        }

        return is_valid, stats

    def _save_to_cache(
        self,
        chapter: Chapter,
        alignment_data: Dict,
        quality_score: float,
        model_name: str,
        template_id: Optional[int],
        coverage_ru: float = 1.0,
        coverage_zh: float = 1.0,
        avg_confidence: float = 1.0
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –ë–î"""
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –µ—Å—Ç—å
        BilingualAlignment.query.filter_by(chapter_id=chapter.id).delete()

        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        alignments = alignment_data.get('alignments', [])
        misalignment_count = sum(1 for pair in alignments if pair.get('confidence', 1.0) < 0.7)

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
        alignment = BilingualAlignment(
            chapter_id=chapter.id,
            alignment_data=alignment_data,
            alignment_method='llm',
            model_used=model_name,
            template_used_id=template_id,
            quality_score=quality_score,
            coverage_ru=coverage_ru,
            coverage_zh=coverage_zh,
            avg_confidence=avg_confidence,
            total_pairs=len(alignments),
            misalignment_count=misalignment_count
        )

        db.session.add(alignment)
        db.session.commit()

        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –∫—ç—à –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è –≥–ª–∞–≤—ã {chapter.id} (quality={quality_score:.2f})")

    def _create_monolingual_alignment(self, russian_text: str) -> List[Dict]:
        """Fallback: —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ"""
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = [p.strip() for p in russian_text.split('\n\n') if p.strip()]

        return [
            {
                'ru': para,
                'zh': '',
                'type': 'description',
                'confidence': 1.0
            }
            for para in paragraphs
        ]

    def _fallback_regex_alignment(
        self,
        russian_text: str,
        chinese_text: str,
        chapter: Chapter
    ) -> List[Dict]:
        """Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π regex-–º–µ—Ç–æ–¥ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö LLM"""
        log_prefix = f"[Novel:{chapter.novel_id}, Ch:{chapter.chapter_number}]"
        LogService.log_warning(
            f"{log_prefix} –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback regex-–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ",
            novel_id=chapter.novel_id,
            chapter_id=chapter.id
        )

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
        from app.utils.text_alignment import BilingualTextAligner

        aligned_pairs = BilingualTextAligner.align_sentences(russian_text, chinese_text)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
        result = [
            {
                'ru': ru,
                'zh': zh,
                'type': 'unknown',
                'confidence': 0.5
            }
            for ru, zh in aligned_pairs
        ]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à —Å –ø–æ–º–µ—Ç–∫–æ–π regex
        alignment_data = {
            'alignments': result,
            'stats': {
                'total_pairs': len(result),
                'method': 'regex_fallback'
            }
        }

        self._save_to_cache(
            chapter=chapter,
            alignment_data=alignment_data,
            quality_score=0.5,  # –ù–∏–∑–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è regex
            model_name='regex_fallback',
            template_id=None
        )

        return result

    def regenerate_alignment(self, chapter: Chapter) -> List[Dict]:
        """
        –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ (—É–¥–∞–ª–∏—Ç—å –∫—ç—à –∏ —Å–æ–∑–¥–∞—Ç—å –∑–∞–Ω–æ–≤–æ)

        Args:
            chapter: –ì–ª–∞–≤–∞ –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è

        Returns:
            List[Dict]: –ù–æ–≤–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
        """
        log_prefix = f"[Novel:{chapter.novel_id}, Ch:{chapter.chapter_number}]"
        LogService.log_info(
            f"{log_prefix} –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (—É–¥–∞–ª–µ–Ω–∏–µ –∫—ç—à–∞)",
            novel_id=chapter.novel_id,
            chapter_id=chapter.id
        )

        # –£–¥–∞–ª—è–µ–º –∫—ç—à
        BilingualAlignment.query.filter_by(chapter_id=chapter.id).delete()
        db.session.commit()

        # –°–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ
        return self.align_chapter(chapter, force_refresh=True, save_to_cache=True)

    def get_alignment_preview(self, chapter: Chapter, max_pairs: int = 5) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–≤—å—é –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI

        Args:
            chapter: –ì–ª–∞–≤–∞
            max_pairs: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –¥–ª—è –ø—Ä–µ–≤—å—é

        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏ –¥–ª—è UI
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—ç—à–∞
        cached = BilingualAlignment.query.filter_by(chapter_id=chapter.id).first()

        if cached:
            alignments = cached.alignment_data.get('alignments', [])
            preview_pairs = alignments[:max_pairs]

            return {
                'cached': True,
                'quality_score': cached.quality_score,
                'total_pairs': cached.total_pairs,
                'coverage_ru': cached.coverage_ru,
                'coverage_zh': cached.coverage_zh,
                'avg_confidence': cached.avg_confidence,
                'method': cached.alignment_method,
                'model_used': cached.model_used,
                'needs_review': cached.needs_review,
                'is_high_quality': cached.is_high_quality,
                'preview_pairs': preview_pairs,
                'created_at': cached.created_at.isoformat() if cached.created_at else None
            }
        else:
            return {
                'cached': False,
                'message': '–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ. –ù–∞–∂–º–∏—Ç–µ "–°–æ–∑–¥–∞—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ" –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.'
            }
